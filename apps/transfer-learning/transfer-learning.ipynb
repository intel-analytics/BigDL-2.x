{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the image transfer learning example, we use a pre-trained Inception_V1 model as image feature transformer and train another linear classifier to solve the dogs-vs-cats classification problem.\n",
    "\n",
    "In this notebook we are going to take a slightly different approach. We will still use a pre-trained Inception_V1 model, but this time we will operate on the pre-trained model to freeze first of a few layers, replace the classifier on the top, then fine tune the whole model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the training dataset from https://www.kaggle.com/c/dogs-vs-cats and extract it. \n",
    "\n",
    "The following commands copy about 1100 images of cats and dogs into demo/cats and demo/dogs separately. \n",
    "```\n",
    "mkdir -p demo/dogs\n",
    "mkdir -p demo/cats\n",
    "cp train/cat.7* demo/cats\n",
    "cp train/dog.7* demo/dogs\n",
    "```\n",
    "\n",
    "Download the pre-trained Inception-V1 model from [Zoo](https://s3-ap-southeast-1.amazonaws.com/bigdl-models/imageclassification/imagenet/bigdl_inception-v1_imagenet_0.4.0.model) \n",
    " Alternatively, user may also download pre-trained caffe/Tensorflow/keras model. Please refer to programming guide in  [BigDL](https://bigdl-project.github.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createDefault\n",
      "creating: createSGD\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from bigdl.nn.criterion import CrossEntropyCriterion\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "\n",
    "from zoo.common.nncontext import *\n",
    "from zoo.feature.image import *\n",
    "from zoo.pipeline.api.keras.layers import Dense, Input, Flatten\n",
    "from zoo.pipeline.api.keras.models import *\n",
    "from zoo.pipeline.api.net import *\n",
    "from zoo.pipeline.nnframes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkConf = SparkConf().setAppName(\"ImageTransferLearningExample\")\n",
    "sc = get_nncontext(sparkConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "u\"Error while instantiating 'org.apache.spark.sql.hive.HiveSessionState':\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9e641a536147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/xiaxue/data/bigdl_inception-v1_imagenet_0.4.0.model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/xiaxue/data/demo/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimageDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNImageReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/spark-ff3fcf7b-2435-4a07-80f2-05c5e7b72dd8/userFiles-e5184e12-94f1-4b16-a432-29824d0559bd/analytics-zoo-0.1.0-SNAPSHOT-python-api.zip/zoo/pipeline/nnframes/nn_image_reader.py\u001b[0m in \u001b[0;36mreadImages\u001b[0;34m(path, sc, minPartitions, bigdl_type)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mone\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRow\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCvType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallBigDlFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigdl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nnReadImage\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminPartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/spark-ff3fcf7b-2435-4a07-80f2-05c5e7b72dd8/userFiles-e5184e12-94f1-4b16-a432-29824d0559bd/analytics-zoo-0.1.0-SNAPSHOT-python-api.zip/bigdl/util/common.py\u001b[0m in \u001b[0;36mcallBigDlFunc\u001b[0;34m(bigdl_type, name, *args)\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"does not exist\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: u\"Error while instantiating 'org.apache.spark.sql.hive.HiveSessionState':\""
     ]
    }
   ],
   "source": [
    "from bigdl.util.common import callBigDlFunc\n",
    "model_path = \"/home/xiaxue/data/bigdl_inception-v1_imagenet_0.4.0.model\"\n",
    "image_path = \"/home/xiaxue/data/demo/\"\n",
    "imageDF = NNImageReader.readImages(image_path, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-c5fafb8cd4b5>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-c5fafb8cd4b5>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    StringType())$\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "getName = udf(lambda row:\n",
    "                  re.search(r'(cat|dog)\\.([\\d]*)\\.jpg', row[0], re.IGNORECASE).group(0),\n",
    "                  StringType())$\n",
    "getLabel = udf(lambda name: 1.0 if name.startswith('cat') else 2.0, DoubleType())\n",
    "labelDF = imageDF.withColumn(\"name\", getName(col(\"image\"))) \\\n",
    "        .withColumn(\"label\", getLabel(col('name')))\n",
    "(trainingDF, validationDF) = labelDF.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compose a pipeline that includes feature transform, pretrained model and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createRowToImageFeature\n",
      "creating: createImageResize\n",
      "creating: createImageCenterCrop\n",
      "creating: createImageChannelNormalize\n",
      "creating: createImageMatToTensor\n",
      "creating: createImageFeatureToTensor\n",
      "creating: createChainedPreprocessing\n"
     ]
    }
   ],
   "source": [
    "transformer = ChainedPreprocessing(\n",
    "        [RowToImageFeature(), ImageResize(256, 256), ImageCenterCrop(224, 224),\n",
    "         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageFeatureToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Model' has no attribute 'loadModel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-12144fcd2fbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreTrainedNNModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0msetFeaturesCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0msetPredictionCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Model' has no attribute 'loadModel'"
     ]
    }
   ],
   "source": [
    "preTrainedNNModel = NNModel(Model.loadModel(model_path), transformer) \\\n",
    "        .setFeaturesCol(\"image\") \\\n",
    "        .setPredictionCol(\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createZooKerasSequential\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Linear' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-65333d41b077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlrModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogSoftMax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassNLLCriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeqToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0msetLearningRate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetBatchSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetMaxEpoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetFeaturesCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Linear' is not defined"
     ]
    }
   ],
   "source": [
    "lrModel = Sequential().add(Linear(1000, 2)).add(LogSoftMax())\n",
    "classifier = NNClassifier(lrModel, ClassNLLCriterion(), SeqToTensor([1000])) \\\n",
    "        .setLearningRate(0.003).setBatchSize(40).setMaxEpoch(20).setFeaturesCol(\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preTrainedNNModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-11a6e5ecc671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreTrainedNNModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'preTrainedNNModel' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[preTrainedNNModel, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-87a30cf40940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcatdogModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictionDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatdogModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidationDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredictionDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "catdogModel = pipeline.fit(trainingDF)\n",
    "predictionDF = catdogModel.transform(validationDF).cache()\n",
    "predictionDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MulticlassClassificationEvaluator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2b5e9eefaba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m evaluator = MulticlassClassificationEvaluator(\n\u001b[0m\u001b[1;32m      2\u001b[0m         labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n\u001b[1;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictionDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MulticlassClassificationEvaluator' is not defined"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictionDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expected error should be less than 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6a76f5b1ba8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Error = %g \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Test Error = %g \" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
