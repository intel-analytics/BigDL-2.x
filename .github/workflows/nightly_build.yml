name: Nightly Build

on:
  # pull_request:
  #   branches: [ main ]
  #   paths:
  #     - '.github/workflows/nightly_build.yml'
  # schedule:
  #   - cron: '30 11 * * *'  # GMT time, 11:30 GMT == 19:30 China
  workflow_dispatch:
    inputs:
      artifact:
        description: 'select which job to run("all" will make all jobs run)'
        required: true
        default: 'all'
        type: choice
        options:
        - all
        - scala-build
        - python-sourceforge-build
        - docker-bigdl-build
      tag:
        description: 'docker image tag (e.g. 2.1.0-SNAPSHOT)'
        required: true
        default: 'latest'
        type: string
env:
  GIST_ID: 48dbd87983219d4fe264adfea701815a

permissions:
  contents: read

jobs:

  scala-build:
    if: ${{ github.event.schedule || github.event.inputs.artifact == 'scala-build' || github.event.inputs.artifact == 'docker-bigdl-build' || github.event.inputs.artifact == 'all' }}
    runs-on: [self-hosted, Bree]

    steps:
    - uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # actions/checkout@v3
    
    - name: Set up JDK8
      uses: ./.github/actions/jdk-setup-action

    - name: Set up Maven
      uses: stCarolas/setup-maven@v4.4
      with:
        maven-version: 3.8.2

    - name: Set up Maven Settings	
      uses: s4u/maven-settings-action@v2.8.0	
      with:	
        sonatypeSnapshots: true	
        apacheSnapshots: true	
        proxies: |
          [{
            "id": "us-http", 
            "active": "true", 
            "protocol": "http", 
            "host": "${{ secrets.HTTP_PROXY_HOST_2 }}", 
            "port": "${{ secrets.HTTP_PROXY_PORT_2 }}", 
            "nonProxyHosts": "${{ secrets.NO_PROXY }}|localhost"
          },{
            "id": "us-https", 
            "active": "true", 
            "protocol": "https", 
            "host": "${{ secrets.HTTP_PROXY_HOST_2 }}", 
            "port": "${{ secrets.HTTP_PROXY_PORT_3 }}", 
            "nonProxyHosts": "${{ secrets.NO_PROXY }}|localhost"
          }]
        servers: |
          [{
            "id": "central",
            "configuration": {
              "httpConfiguration": {
                "all": {
                  "connectionTimeout": "3600000",
                  "readTimeout": "3600000"
                  }    
                }
              }
          },{
            "id": "ossrh",
            "username": "${{ secrets.OSSRH_USERNAME }}",
            "password": "${{ secrets.OSSRH_PASSWORD }}",
            "configuration": {
              "timeout": "3600000"
            }
          }]
          
    - name: Build with Maven
      run: |
          ls
          #spark3.4.1
          cp scala/pom.xml scala/pom.xml.origin
          cp scala/common/spark-version/pom.xml scala/common/spark-version/pom.xml.origin
          cp scala/common/spark-version/3.0/pom.xml scala/common/spark-version/3.0/pom.xml.origin
          cp scala/dllib/pom.xml scala/dllib/pom.xml.origin
          cp scala/orca/pom.xml scala/orca/pom.xml.origin
          cp scala/friesian/pom.xml scala/friesian/pom.xml.origin
          cp scala/grpc/pom.xml scala/grpc/pom.xml.origin
          cp scala/serving/pom.xml scala/serving/pom.xml.origin
          cp scala/ppml/pom.xml scala/ppml/pom.xml.origin
          cp scala/assembly/pom.xml scala/assembly/pom.xml.origin

          sed -i 's/<artifactId>${spark-version.project}<\/artifactId>/<artifactId>${spark-version.project}-${SPARK_PLATFORM}<\/artifactId>/' scala/dllib/pom.xml
          sed -i 's/<artifactId>3.0<\/artifactId>/<artifactId>3.0-${SPARK_PLATFORM}<\/artifactId>/' scala/common/spark-version/3.0/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_3.4.1<\/artifactId>/' scala/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_3.4.1<\/artifactId>/' scala/common/spark-version/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_3.4.1<\/artifactId>/' scala/common/spark-version/3.0/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_3.4.1<\/artifactId>/' scala/dllib/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_3.4.1<\/artifactId>/' scala/orca/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_3.4.1<\/artifactId>/' scala/friesian/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_3.4.1<\/artifactId>/' scala/grpc/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_3.4.1<\/artifactId>/' scala/serving/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_3.4.1<\/artifactId>/' scala/ppml/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_3.4.1<\/artifactId>/' scala/assembly/pom.xml
          mvn -Dhttp.proxyHost=${{ secrets.HTTP_PROXY_HOST_2 }} -Dhttp.proxyPort=${{ secrets.HTTP_PROXY_PORT_2 }} -Dhttps.proxyHost=${{ secrets.HTTP_PROXY_HOST_2 }} -Dhttps.proxyPort=${{ secrets.HTTP_PROXY_PORT_3 }} clean deploy -DskipTests -Dspark.version=3.4.1 -DSPARK_PLATFORM=SPARK_3.4 -P spark_3.x -P sign --file scala/pom.xml
      
          mv scala/pom.xml.origin scala/pom.xml
          mv scala/common/spark-version/pom.xml.origin scala/common/spark-version/pom.xml
          mv scala/common/spark-version/3.0/pom.xml.origin scala/common/spark-version/3.0/pom.xml
          mv scala/dllib/pom.xml.origin scala/dllib/pom.xml
          mv scala/orca/pom.xml.origin scala/orca/pom.xml
          mv scala/friesian/pom.xml.origin scala/friesian/pom.xml
          mv scala/grpc/pom.xml.origin scala/grpc/pom.xml
          mv scala/serving/pom.xml.origin scala/serving/pom.xml
          mv scala/ppml/pom.xml.origin scala/ppml/pom.xml
          mv scala/assembly/pom.xml.origin scala/assembly/pom.xml

          #spark2.4.6          
          cp scala/pom.xml scala/pom.xml.origin
          cp scala/common/spark-version/pom.xml scala/common/spark-version/pom.xml.origin
          cp scala/common/spark-version/2.0/pom.xml scala/common/spark-version/2.0/pom.xml.origin
          cp scala/dllib/pom.xml scala/dllib/pom.xml.origin
          cp scala/orca/pom.xml scala/orca/pom.xml.origin
          cp scala/friesian/pom.xml scala/friesian/pom.xml.origin
          cp scala/grpc/pom.xml scala/grpc/pom.xml.origin
          cp scala/serving/pom.xml scala/serving/pom.xml.origin
          cp scala/ppml/pom.xml scala/ppml/pom.xml.origin
          cp scala/assembly/pom.xml scala/assembly/pom.xml.origin

          sed -i 's/<artifactId>${spark-version.project}<\/artifactId>/<artifactId>${spark-version.project}-${SPARK_PLATFORM}<\/artifactId>/' scala/dllib/pom.xml
          sed -i 's/<artifactId>2.0<\/artifactId>/<artifactId>2.0-${SPARK_PLATFORM}<\/artifactId>/' scala/common/spark-version/2.0/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_2.4.6<\/artifactId>/' scala/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_2.4.6<\/artifactId>/' scala/common/spark-version/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_2.4.6<\/artifactId>/' scala/common/spark-version/2.0/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_2.4.6<\/artifactId>/' scala/dllib/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_2.4.6<\/artifactId>/' scala/orca/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_2.4.6<\/artifactId>/' scala/friesian/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_2.4.6<\/artifactId>/' scala/grpc/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_2.4.6<\/artifactId>/' scala/serving/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_2.4.6<\/artifactId>/' scala/ppml/pom.xml
          sed -i 's/<artifactId>bigdl-parent-spark_${spark.version}<\/artifactId>/<artifactId>bigdl-parent-spark_2.4.6<\/artifactId>/' scala/assembly/pom.xml
          mvn -Dhttp.proxyHost=${{ secrets.HTTP_PROXY_HOST_2 }} -Dhttp.proxyPort=${{ secrets.HTTP_PROXY_PORT_2 }} -Dhttps.proxyHost=${{ secrets.HTTP_PROXY_HOST_2 }} -Dhttps.proxyPort=${{ secrets.HTTP_PROXY_PORT_3 }} clean deploy -DskipTests -Dspark.version=2.4.6 -DSPARK_PLATFORM=SPARK_2.4 -P spark_2.x -P sign --file scala/pom.xml
     
          mv scala/pom.xml.origin scala/pom.xml
          mv scala/common/spark-version/pom.xml.origin scala/common/spark-version/pom.xml
          mv scala/common/spark-version/2.0/pom.xml.origin scala/common/spark-version/2.0/pom.xml
          mv scala/dllib/pom.xml.origin scala/dllib/pom.xml
          mv scala/orca/pom.xml.origin scala/orca/pom.xml
          mv scala/friesian/pom.xml.origin scala/friesian/pom.xml
          mv scala/grpc/pom.xml.origin scala/grpc/pom.xml
          mv scala/serving/pom.xml.origin scala/serving/pom.xml
          mv scala/ppml/pom.xml.origin scala/ppml/pom.xml
          mv scala/assembly/pom.xml.origin scala/assembly/pom.xml

    - name: Create Job Badge
      uses: ./.github/actions/create-job-status-badge
      if: ${{ always() }}
      with:
        secret: ${{ secrets.GIST_SECRET}}
        gist-id: ${{env.GIST_ID}}
        is-self-hosted-runner: true
        file-name: nb-scala-build.json
        type: job
        job-name: scala-build
        runner-hosted-on: 'Shanghai'

  docker-build-bigdl:
    needs: scala-build
    if: ${{ github.event.schedule || github.event.inputs.artifact == 'docker-bigdl-build' || github.event.inputs.artifact == 'all' }} 
    runs-on: [self-hosted, Shire]

    steps:
    - uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # actions/checkout@v3
    - name: set env
      env:
        DEFAULT_TAG: 'latest'
      run: |
        echo "TAG=${{ github.event.inputs.bigdlTag || env.DEFAULT_TAG }}" >> $GITHUB_ENV
    - name: docker login
      run: |
        docker login -u ${DOCKERHUB_USERNAME} -p ${DOCKERHUB_PASSWORD}
    - name: docker deploy bigdl
      run: |
        export IMAGE=intelanalytics/bigdl
        cd docker/bigdl
        echo "########################################"
        echo "################# bigdl 3.4.1 #######"
        echo "########################################"
        docker build \
          --build-arg http_proxy=${HTTP_PROXY} \
          --build-arg https_proxy=${HTTPS_PROXY} \
          --build-arg SPARK_VERSION=3.4.1 \
          --build-arg HADOOP_VERSION=3 \
          --build-arg JDK_VERSION=8u192 \
          --build-arg JDK_URL=${JDK_URL} \
          --build-arg no_proxy=${NO_PROXY} \
          --rm --no-cache -t $IMAGE-spark-3.4.1:${TAG} .
        # tag 'latest'
        docker push ${IMAGE}-spark-3.4.1:${TAG}
        docker tag ${IMAGE}-spark-3.4.1:${TAG} 10.239.45.10/arda/${IMAGE}-spark-3.4.1:${TAG}
        docker push 10.239.45.10/arda/${IMAGE}-spark-3.4.1:${TAG}
        # tag SNAPSHOT
        export TAG_SNAPSHOT=2.5.0-SNAPSHOT
        docker tag 10.239.45.10/arda/${IMAGE}-spark-3.4.1:${TAG} ${IMAGE}-spark-3.4.1:${TAG_SNAPSHOT}
        docker push ${IMAGE}-spark-3.4.1:${TAG_SNAPSHOT} 
        docker rmi -f ${IMAGE}-spark-3.4.1:${TAG} 10.239.45.10/arda/${IMAGE}-spark-3.4.1:${TAG} ${IMAGE}-spark-3.4.1:${TAG_SNAPSHOT}
    - name: docker deploy bigdl-k8s
      run: |
        cd docker/bigdl-k8s
        export IMAGE=intelanalytics/bigdl-k8s
        export TAG=latest
        echo "########################################"
        echo "################# bigdl-k8s 3.4.1 #######"
        echo "########################################"
        docker build \
        --build-arg http_proxy=${HTTP_PROXY} \
        --build-arg https_proxy=${HTTPS_PROXY} \
        --build-arg SPARK_VERSION=3.4.1 \
        --build-arg HADOOP_VERSION=3 \
        --build-arg JDK_VERSION=8u192 \
        --build-arg JDK_URL=${JDK_URL} \
        --build-arg no_proxy=${NO_PROXY} \
        --rm --no-cache -t ${IMAGE}-spark-3.4.1:${TAG} .
        # tag 'latest'
        docker push ${IMAGE}-spark-3.4.1:${TAG}
        docker tag ${IMAGE}-spark-3.4.1:${TAG} ${IMAGE}:${TAG}
        docker push ${IMAGE}:${TAG}
        docker tag ${IMAGE}:${TAG} 10.239.45.10/arda/${IMAGE}-spark-3.4.1:${TAG}
        docker push 10.239.45.10/arda/${IMAGE}-spark-3.4.1:${TAG}
        # tag SNAPSHOT
        export TAG_SNAPSHOT=2.5.0-SNAPSHOT
        docker tag 10.239.45.10/arda/${IMAGE}-spark-3.4.1:${TAG} ${IMAGE}:${TAG_SNAPSHOT}
        docker push ${IMAGE}:${TAG_SNAPSHOT}
        docker rmi -f ${IMAGE}-spark-3.4.1:${TAG} ${IMAGE}:${TAG} 10.239.45.10/arda/${IMAGE}-spark-3.4.1:${TAG} ${IMAGE}:${TAG_SNAPSHOT}
    - name: docker deploy bigdl-chronos
      run: |
        mv docker/chronos-nightly/Dockerfile ./Dockerfile
        export IMAGE=intelanalytics/bigdl-chronos
        export TAG=latest
        echo "########################################"
        echo "################# bigdl-chronos #######"
        echo "########################################"
        docker build \
        --build-arg http_proxy=${HTTP_PROXY} \
        --build-arg https_proxy=${HTTPS_PROXY} \
        --rm --no-cache -t ${IMAGE}:${TAG} .
        # tag 'latest'
        docker push ${IMAGE}:${TAG}
        docker tag ${IMAGE}:${TAG} 10.239.45.10/arda/${IMAGE}:${TAG}
        docker push 10.239.45.10/arda/${IMAGE}:${TAG}
        # tag SNAPSHOT
        export TAG_SNAPSHOT=2.5.0-SNAPSHOT
        docker tag 10.239.45.10/arda/${IMAGE}:${TAG} ${IMAGE}:${TAG_SNAPSHOT}
        docker push ${IMAGE}:${TAG_SNAPSHOT}
        docker rmi -f ${IMAGE}:${TAG_SNAPSHOT} ${IMAGE}:${TAG} 10.239.45.10/arda/${IMAGE}:${TAG}
        mv ./Dockerfile docker/chronos-nightly/Dockerfile
    - name: docker deploy bigdl-orca
      run: |
        cd docker/orca
        export IMAGE=intelanalytics/bigdl-orca
        export TAG=latest
        echo "########################################"
        echo "################# bigdl-orca ###########"
        echo "########################################"
        docker build \
        --build-arg http_proxy=${HTTP_PROXY} \
        --build-arg https_proxy=${HTTPS_PROXY} \
        --build-arg JDK_VERSION=8u192 \
        --build-arg JDK_URL=${JDK_URL} \
        --build-arg no_proxy=${NO_PROXY} \
        --build-arg SPARK_VERSION=3.4.1 \
        --build-arg HADOOP_VERSION=3 \
        --build-arg PY4J_VERSION=0.10.9 \
        --rm --no-cache -t ${IMAGE}:${TAG} .
        # tag 'latest'
        docker push ${IMAGE}:${TAG}
        docker tag ${IMAGE}:${TAG} 10.239.45.10/arda/${IMAGE}:${TAG}
        docker push 10.239.45.10/arda/${IMAGE}:${TAG}
        # tag SNAPSHOT
        export TAG_SNAPSHOT=2.5.0-SNAPSHOT
        docker tag 10.239.45.10/arda/${IMAGE}:${TAG} ${IMAGE}:${TAG_SNAPSHOT}
        docker push ${IMAGE}:${TAG_SNAPSHOT}
        docker rmi -f ${IMAGE}:${TAG_SNAPSHOT} ${IMAGE}:${TAG} 10.239.45.10/arda/${IMAGE}:${TAG}

    - name: Create Job Badge
      if: ${{ always() }}
      uses: ./.github/actions/create-job-status-badge
      with:
        secret: ${{ secrets.GIST_SECRET }}
        gist-id: ${{env.GIST_ID}}
        is-self-hosted-runner: true
        file-name: nb-docker-build-bigdl.json
        type: job
        job-name: docker-build-bigdl
        runner-hosted-on: 'Shanghai'
  
  llm-cpp-build:
    uses: ./.github/workflows/llm-binary-build.yml

  python-build:
    # python build can only be published once a day, please do not publish it manually
    if: ${{ github.event.schedule || github.event.inputs.artifact == 'all'}} 
    runs-on: [self-hosted, Bree]
    needs: llm-cpp-build
    steps:
    - uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # actions/checkout@v3
    - name: Set up JDK8
      uses: ./.github/actions/jdk-setup-action

    - name: Set up maven
      uses: ./.github/actions/maven-setup-action

    - name: Set up Python 
      uses: actions/setup-python@v2
      with:
        python-version: '3.7.15'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build
        pip install wheel
        pip install twine
    - name: Download llm binary
      uses: ./.github/actions/llm/download-llm-binary
    - name: Build package
      run: |
        export TIMESTAMP=`date '+%Y%m%d'`
        export PYPI_VERSION=2.5.0
        nb_version=${PYPI_VERSION}b${TIMESTAMP}
        echo ${nb_version}

        ## windows ##
        bash python/dev/release_default_windows.sh ${nb_version} false true

        ## linux ##
        bash python/dev/release_default_linux.sh ${nb_version} true

        ## mac ##
        bash python/dev/release_default_mac.sh ${nb_version} true

    - name: Create Job Badge
      if: ${{ always() }}
      uses: ./.github/actions/create-job-status-badge
      with:
        secret: ${{ secrets.GIST_SECRET }}
        gist-id: ${{env.GIST_ID}}
        is-self-hosted-runner: true
        file-name: nb-python-build.json
        type: job
        job-name: python-build
        runner-hosted-on: 'Shanghai'

  python-sourceforge-build:
    if: ${{ github.event.schedule || github.event.inputs.artifact == 'python-sourceforge-build' || github.event.inputs.artifact == 'all' }} 
    runs-on: [self-hosted, Bree]

    steps:
    - uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # actions/checkout@v3
    - name: Set up JDK8
      uses: ./.github/actions/jdk-setup-action
    - name: Set up maven
      uses: ./.github/actions/maven-setup-action
    - name: Set up Python 
      uses: actions/setup-python@v2
      with:
        python-version: '3.7.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build
        pip install wheel
        pip install twine
    
    - name: Build package
      run: |
        export TIMESTAMP=`date '+%Y%m%d'`
        export PYPI_VERSION=2.5.0
        nb_version=${PYPI_VERSION}b${TIMESTAMP}
        echo ${nb_version}
        apt-get update
        apt-get install sshpass
        #spark2
        ## linux ##
        bash python/dev/release_default_linux_spark2.sh ${nb_version} false false
        
        # upload
        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/dllib/src/dist/bigdl_dllib*-py3-none-manylinux1_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/dllib-py

        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/orca/src/dist/bigdl_orca*-py3-none-manylinux1_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/orca-py

        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/friesian/src/dist/bigdl_friesian*-py3-none-manylinux1_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/friesian-py

        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/chronos/src/dist/bigdl_chronos*-py3-none-manylinux1_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/chronos-py

        #sshpass -p "${SOURCEFORGE_PW}" \
        #scp ./python/serving/src/dist/bigdl_serving*-py2.py3-none-any.whl \
        #intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/cluster-serving-py
        echo "test mac build"
        
        ## mac ##
        bash python/dev/release_default_mac_spark2.sh ${nb_version} false false

        # upload
        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/dllib/src/dist/bigdl_dllib*-py3-none-macosx_10_11_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/dllib-py

        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/orca/src/dist/bigdl_orca*-py3-none-macosx_10_11_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/orca-py

        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/friesian/src/dist/bigdl_friesian*-py3-none-macosx_10_11_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/friesian-py

        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/chronos/src/dist/bigdl_chronos*-py3-none-macosx_10_11_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/chronos-py

        #spark3
        ## linux ##
        bash python/dev/release_default_linux_spark3.sh ${nb_version} false false
        # upload
        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/dllib/src/dist/bigdl_dllib*-py3-none-manylinux1_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/dllib-py-spark3

        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/orca/src/dist/bigdl_orca*-py3-none-manylinux1_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/orca-py-spark3

        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/friesian/src/dist/bigdl_friesian*-py3-none-manylinux1_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/friesian-py-spark3

        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/chronos/src/dist/bigdl_chronos*-py3-none-manylinux1_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/chronos-py-spark3

        ## mac ##
        bash python/dev/release_default_mac_spark3.sh ${nb_version} false false
        # upload
        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/dllib/src/dist/bigdl_dllib*-py3-none-macosx_10_11_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/dllib-py-spark3

        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/orca/src/dist/bigdl_orca*-py3-none-macosx_10_11_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/orca-py-spark3

        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/friesian/src/dist/bigdl_friesian*-py3-none-macosx_10_11_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/friesian-py-spark3

        sshpass -p "${SOURCEFORGE_PW}" \
        scp ./python/chronos/src/dist/bigdl_chronos*-py3-none-macosx_10_11_x86_64.whl \
        intelanalytics@frs.sourceforge.net:/home/frs/project/analytics-zoo/chronos-py-spark3

    - name: Create Job Badge
      if: ${{ always() }}
      uses: ./.github/actions/create-job-status-badge
      with:
        secret: ${{ secrets.GIST_SECRET }}
        gist-id: ${{env.GIST_ID}}
        is-self-hosted-runner: true
        file-name: nb-python-sourceforge-build.json
        type: job
        job-name: python-build-sourceforge
        runner-hosted-on: 'Shanghai'

  create-workflow-badge:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # actions/checkout@v3
    - name: create workflow badge
      if: ${{ always() }}
      uses: ./.github/actions/create-job-status-badge
      with:
        secret: ${{ secrets.GIST_SECRET }}
        gist-id: ${{env.GIST_ID}}
        file-name: nightly-build.json
        type: workflow