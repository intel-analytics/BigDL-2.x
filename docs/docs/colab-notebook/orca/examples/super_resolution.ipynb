{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "super_resolution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUDslOzK7jyOCefTH2XxVF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/intel-analytics/analytics-zoo/blob/master/docs/docs/colab-notebook/orca/examples/super_resolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#\n",
        "# Copyright 2018 Analytics Zoo Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "# This example trains a super-resolution network on the BSD300 dataset,\n",
        "# using crops from the 200 training images, and evaluating on crops of the 100 test images,\n",
        "# and is adapted from\n",
        "# https://github.com/pytorch/examples/tree/master/super_resolution\n",
        "#"
      ],
      "outputs": [],
      "metadata": {
        "id": "K9l8_mtY64CL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Environment Preparation**\n",
        "\n",
        "**Install Java 8**\n",
        "\n",
        "Run the cell on the **Google Colab** to install jdk 1.8.\n",
        "\n",
        "**Note:** if you run this notebook on your computer, root permission is required when running the cell to install Java 8. (You may ignore this cell if Java 8 has already been set up in your computer)."
      ],
      "metadata": {
        "id": "ResW0PSY4xWC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Install jdk8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "# Set environment variable JAVA_HOME.\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ],
      "outputs": [],
      "metadata": {
        "id": "R0p4mAbe0iH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install Analytics Zoo**\n",
        "\n",
        "[Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) is needed to prepare the Python environment for running this example. \n",
        "\n",
        "**Note**: The following code cell is specific for setting up conda environment on Colab; for general conda installation, please refer to the [install guide](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) for more details."
      ],
      "metadata": {
        "id": "T-dVmMas8KfK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import sys\n",
        "\n",
        "# Get current python version\n",
        "version_info = sys.version_info\n",
        "python_version = f\"{version_info.major}.{version_info.minor}.{version_info.micro}\""
      ],
      "outputs": [],
      "metadata": {
        "id": "69suYs9K0kiu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Install Miniconda\n",
        "!wget https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "# Update Conda\n",
        "!conda install --channel defaults conda python=$python_version --yes\n",
        "!conda update --channel defaults --all --yes\n",
        "\n",
        "# Append to the sys.path\n",
        "_ = (sys.path\n",
        "        .append(f\"/usr/local/lib/python{version_info.major}.{version_info.minor}/site-packages\"))\n",
        "\n",
        "os.environ['PYTHONHOME']=\"/usr/local\""
      ],
      "outputs": [],
      "metadata": {
        "id": "JIqTR4zuTuHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can install the latest pre-release version using `pip install --pre  analytics-zoo`."
      ],
      "metadata": {
        "id": "IaopMtV98hB-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Install latest pre-release version of Analytics Zoo \n",
        "# For bigdl backend\n",
        "!pip install --pre --upgrade analytics-zoo"
      ],
      "outputs": [],
      "metadata": {
        "id": "tUGTC8lT07ZE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Install torchvision by conda\n",
        "!pip install tqdm\n",
        "!conda install pytorch torchvision cpuonly -c pytorch -y"
      ],
      "outputs": [],
      "metadata": {
        "id": "M6cZpzM4hPIP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Install required dependencies\n",
        "!pip install pillow\n",
        "!pip install jep==3.9.0\n",
        "!pip install cloudpickle\n",
        "!pip install tensorboardx==2.2\n",
        "!pip install tb-nightly"
      ],
      "outputs": [],
      "metadata": {
        "id": "gxSHPvimz9_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Distributed Pytorch using Orca APIs**\n",
        "\n",
        "In this guide we will describe how to scale out PyTorch programs using Orca in 5 simple steps."
      ],
      "metadata": {
        "id": "5mo8uojl9rQN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#import necessary libraries and modules\n",
        "import numpy as np\n",
        "\n",
        "import urllib\n",
        "import tarfile\n",
        "from os import makedirs, remove, listdir\n",
        "from os.path import exists, join, basename\n",
        "\n",
        "from zoo.orca import init_orca_context, stop_orca_context\n",
        "from zoo.orca import OrcaContext"
      ],
      "outputs": [],
      "metadata": {
        "id": "D-mCzxMaN-Fc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1: Init Orca Context**\n"
      ],
      "metadata": {
        "id": "QrFNoK26_Dzp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# recommended to set it to True when running Analytics Zoo in Jupyter notebook. \n",
        "OrcaContext.log_output = True # (this will display terminal's stdout and stderr in the Jupyter notebook).\n",
        "\n",
        "cluster_mode = \"local\"\n",
        "\n",
        "if cluster_mode == \"local\":\n",
        "    init_orca_context(cores=1, memory=\"2g\") # run in local mode\n",
        "elif cluster_mode == \"k8s\":\n",
        "    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=4) # run on K8s cluster\n",
        "elif cluster_mode == \"yarn\":\n",
        "    init_orca_context(\n",
        "        cluster_mode=\"yarn-client\", cores=4, num_nodes=2, memory=\"2g\",\n",
        "        driver_memory=\"10g\", driver_cores=1,\n",
        "        conf={\"spark.rpc.message.maxSize\": \"1024\",\n",
        "              \"spark.task.maxFailures\": \"1\",\n",
        "              \"spark.driver.extraJavaOptions\": \"-Dbigdl.failure.retryTimes=1\"}) # run on Hadoop YARN cluster"
      ],
      "outputs": [],
      "metadata": {
        "id": "cXSqnMoQ24PO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the only place where you need to specify local or distributed mode. View [Orca Context](https://analytics-zoo.readthedocs.io/en/latest/doc/Orca/Overview/orca-context.html) for more details.\n",
        "\n",
        "**Note**: You should export HADOOP_CONF_DIR=/path/to/hadoop/conf/dir when you run on Hadoop YARN cluster."
      ],
      "metadata": {
        "id": "FUOk_SJRSfbD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2: Define the Model**\n",
        "You may define your model, loss and optimizer in the same way as in any standard (single node) PyTorch program."
      ],
      "metadata": {
        "id": "-6q-5q_H_ZFc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, upscale_factor):\n",
        "        super(Net, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
        "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.pixel_shuffle(self.conv4(x))\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv4.weight)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "net = Net(upscale_factor=3)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.01)"
      ],
      "outputs": [],
      "metadata": {
        "id": "L3ANE_oF2VxX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# training parameters\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "epochs = 30\n",
        "thread = 4\n",
        "batch_size = 4\n",
        "test_batch_size = 100\n",
        "upscale_factor = 3"
      ],
      "outputs": [],
      "metadata": {
        "id": "pQrtqGANLFSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 3: Define Train Dataset**\n",
        "\n",
        "**Prepare Dataset**\n",
        "\n",
        "This is an example using the efficient sub-pixel convolution layer to train on [BSDS300 dataset](http://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds), using crops from the 200 training images, and evaluating on crops of the 100 test images. "
      ],
      "metadata": {
        "id": "PR_6N61wADCI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# download dataset\n",
        "def download_report(count, block_size, total_size):\n",
        "    downloaded = count * block_size\n",
        "    percent = 100. * downloaded / total_size\n",
        "    percent = min(100, percent)\n",
        "    print('downloaded %d, %.2f%% completed' % (downloaded, percent))\n",
        "\n",
        "# download image data from the website\n",
        "def download_bsd300(dest=\"./sr_dataset\"):\n",
        "    output_image_dir = join(dest, \"BSDS300/images\")\n",
        "\n",
        "    if not exists(output_image_dir):\n",
        "        makedirs(dest)\n",
        "        url = \"http://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300-images.tgz\"\n",
        "        print(\"downloading url \", url)\n",
        "\n",
        "        file_path = join(dest, basename(url))\n",
        "        urllib.request.urlretrieve(url, file_path, download_report)\n",
        "\n",
        "        print(\"Extracting data\")\n",
        "        with tarfile.open(file_path) as tar:\n",
        "            for item in tar:\n",
        "                tar.extract(item, dest)\n",
        "        remove(file_path)\n",
        "    return output_image_dir\n",
        "\n",
        "# the traning dataset can only be image\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])"
      ],
      "outputs": [],
      "metadata": {
        "id": "sdk4BfMygZWG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class DatasetFromFolder(data.Dataset):\n",
        "    def __init__(self, image_dir, input_transform=None, target_transform=None):\n",
        "        super(DatasetFromFolder, self).__init__()\n",
        "        self.image_filenames = [join(image_dir, x)\n",
        "                                for x in listdir(image_dir) if is_image_file(x)]\n",
        "        self.input_transform = input_transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        input = load_img(self.image_filenames[index])\n",
        "        target = input.copy()\n",
        "        if self.input_transform:\n",
        "            input = self.input_transform(input)\n",
        "        if self.target_transform:\n",
        "            target = self.target_transform(target)\n",
        "        return input, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)"
      ],
      "outputs": [],
      "metadata": {
        "id": "k_qJKcyPfhR3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, CenterCrop, ToTensor, Resize\n",
        "\n",
        "def load_img(filepath):\n",
        "    img = Image.open(filepath).convert('YCbCr')\n",
        "    y, _, _ = img.split()\n",
        "    return y\n",
        "\n",
        "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
        "    return crop_size - (crop_size % upscale_factor)\n",
        "\n",
        "def input_transform(crop_size, upscale_factor):\n",
        "    return Compose([\n",
        "        CenterCrop(crop_size),\n",
        "        Resize(crop_size // upscale_factor),\n",
        "        ToTensor(),\n",
        "    ])\n",
        "\n",
        "def target_transform(crop_size):\n",
        "    return Compose([\n",
        "        CenterCrop(crop_size),\n",
        "        ToTensor(),\n",
        "    ])"
      ],
      "outputs": [],
      "metadata": {
        "id": "Gu6f9MajflwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can define the train and test dataloader using standarad `torch.utils.data.DataLoader` for training by `bigdl` backend."
      ],
      "metadata": {
        "id": "2VhXqp3q9_cr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "root_dir = download_bsd300()\n",
        "\n",
        "train_dir = join(root_dir, \"train\")\n",
        "test_dir = join(root_dir, \"test\")\n",
        "\n",
        "crop_size = calculate_valid_crop_size(256, upscale_factor)\n",
        "\n",
        "train_set = DatasetFromFolder(train_dir,\n",
        "                              input_transform=input_transform(crop_size, upscale_factor),\n",
        "                              target_transform=target_transform(crop_size))\n",
        "\n",
        "test_set =  DatasetFromFolder(test_dir,\n",
        "                              input_transform=input_transform(crop_size, upscale_factor),\n",
        "                              target_transform=target_transform(crop_size))\n",
        "\n",
        "train_loader = DataLoader(dataset=train_set,\n",
        "                          batch_size=batch_size,\n",
        "                          num_workers=thread,\n",
        "                          shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_set,\n",
        "                         batch_size=batch_size,\n",
        "                         num_workers=thread,\n",
        "                         shuffle=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "MFKdKOHofWna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 4: Fit with Orca Estimator**\n",
        "\n",
        "First, Create an Estimator and set its backend to `bigdl`."
      ],
      "metadata": {
        "id": "cKvWhWLrDYPp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from zoo.orca.learn.pytorch import Estimator\n",
        "from zoo.orca.learn.metrics import MSE\n",
        "from zoo.orca.learn.trigger import EveryEpoch\n",
        "\n",
        "estimator = Estimator.from_torch(\n",
        "        model=net,\n",
        "        optimizer=optimizer,\n",
        "        loss=criterion,\n",
        "        metrics=[MSE()],\n",
        "        backend=\"bigdl\"\n",
        "        )\n",
        "\n",
        "# the path of the directory where to save the log files to be parsed by TensorBoard\n",
        "tensorboard_dir = \"runs\"\n",
        "# \"bigdl\" is the application name for tensorboard to save training and validation results under log path\n",
        "estimator.set_tensorboard(tensorboard_dir, \"bigdl\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "q1C5_31C4q_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, fit using the Estimator, it may take a long time to get good performance."
      ],
      "metadata": {
        "id": "Q8QZ2RzQYiUk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "estimator.fit(data=train_loader, epochs=epochs, validation_data=test_loader, checkpoint_trigger=EveryEpoch())"
      ],
      "outputs": [],
      "metadata": {
        "id": "fL9NjhT1d7pP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, evaluate using the Estimator."
      ],
      "metadata": {
        "id": "IpfZGf7DwTJt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from math import log10\n",
        "# PSNR is Peak Signal to Noise Ratio, we convert maximize PSNR to minimize MSE\n",
        "val_stats = estimator.evaluate(data=test_loader)\n",
        "print(\"===> Validation Complete: Avg. PSNR: {:.4f} dB, Avg. Loss: {:.4f}\"\n",
        "          .format(10 * log10(1. / val_stats[\"MSE\"]), val_stats[\"MSE\"]))"
      ],
      "outputs": [],
      "metadata": {
        "id": "BPkOwML8d9ee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The PSNR of this model has reached around 24dB.\n",
        "\n"
      ],
      "metadata": {
        "id": "Dj0tn6pMYJiA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Stop orca context when your program finishes\n",
        "stop_orca_context()"
      ],
      "outputs": [],
      "metadata": {
        "id": "cDBJ-J5XeDbl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 5: Visualization by Tensorboard**\n",
        "\n",
        "TensorBoard is a visualization toolkit for machine learning experimentation. TensorBoard allows tracking and visualizing metrics such as loss and accuracy, visualizing the model graph, viewing histograms, displaying images and much more."
      ],
      "metadata": {
        "id": "8OBlnkPjM80S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "outputs": [],
      "metadata": {
        "id": "9lNnhkX68cqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reach the testing image and apply trained model to fit."
      ],
      "metadata": {
        "id": "_vLXAJJaSTru"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torchvision\n",
        "\n",
        "# plot one random training image\n",
        "img_to_tensor = ToTensor()\n",
        "\n",
        "# input testing image and convert to tensor\n",
        "img = Image.open('sr_dataset/BSDS300/images/test/16077.jpg').convert('YCbCr')\n",
        "y, cb, cr = img.split()\n",
        "test_image = img_to_tensor(y).view(1, -1, y.size[1], y.size[0])\n",
        "\n",
        "# output image after model training and conver to tensor\n",
        "net = estimator.get_model()\n",
        "out = net(test_image).cpu()\n",
        "out_img_y = out[0].detach().numpy()\n",
        "out_img_y *= 255.0\n",
        "out_img_y = out_img_y.clip(0, 255)\n",
        "out_img_y = Image.fromarray(np.uint8(out_img_y[0]), mode='L')\n",
        "\n",
        "out_img_cb = cb.resize(out_img_y.size, Image.BILINEAR)\n",
        "out_img_cr = cr.resize(out_img_y.size, Image.BILINEAR)\n",
        "out_img = Image.merge('YCbCr', [out_img_y, out_img_cb, out_img_cr]).convert('RGB')\n",
        "out_image = img_to_tensor(out_img_y).view(1, -1, out_img_y.size[1], out_img_y.size[0])\n",
        "\n",
        "# create grid of images\n",
        "test_image_grid = torchvision.utils.make_grid(test_image)\n",
        "out_image_grid = torchvision.utils.make_grid(out_image)"
      ],
      "outputs": [],
      "metadata": {
        "id": "xtsuIPGaNBVY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A brief overview of the dashboards shown (tabs in top navigation bar):\n",
        "\n",
        "* The **SCALARS** dashboard shows how the loss and metrics change with every epoch. You can use it to also track training speed, learning rate, and other scalar values.\n",
        "* The **IMAGES** dashboard can  be extremely helpful to sample and examine your input data, or to visualize layer weights and generated tensors. \n"
      ],
      "metadata": {
        "id": "adXtrlX61ayB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "tensorboard_dir = \"runs\"\n",
        "writer = SummaryWriter(tensorboard_dir + '/bigdl/train')\n",
        "\n",
        "# write to tensorboard\n",
        "writer.add_image('output_image', out_image_grid)\n",
        "writer.add_image('test_image', test_image_grid) "
      ],
      "outputs": [],
      "metadata": {
        "id": "jPUgw6U6HS3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you do not need the summary writer anymore, call close() method."
      ],
      "metadata": {
        "id": "PSctDHMnxRue"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "writer.close()"
      ],
      "outputs": [],
      "metadata": {
        "id": "SP_5AP090cP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start TensorBoard, specifying the root log directory you used above. \n",
        "Argument ``logdir`` points to directory where TensorBoard will look to find \n",
        "event files that it can display. TensorBoard will recursively walk \n",
        "the directory structure rooted at logdir, looking for .*tfevents.* files.\n",
        "\n",
        "This dashboard shows how the loss change with every iteration and displays the difference between original image and super resolution image.\n",
        "\n",
        "Super resolution is a method to recover a low-resolution image to a high-resolution image by training the model. The output image could keep more information in a cell unit of a image."
      ],
      "metadata": {
        "id": "ndEszjjuw6HF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%tensorboard --logdir \"/content/runs/bigdl/train\""
      ],
      "outputs": [],
      "metadata": {
        "id": "qyI5lrXoMw9K"
      }
    }
  ]
}