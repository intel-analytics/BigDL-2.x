{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCF Recommender with Explict Feedback using Orca data-preprocessing and TF Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we demostrate how to leverage Orca data preprocessing and TF Estimator to scale python-based preprocessing and Tensorflow Training into Big Data cluster.\n",
    "\n",
    "In this example, we build a neural network recommendation system, Neural Collaborative Filtering(NCF) with explict feedback. \n",
    "\n",
    "We use Orca preprocessing to do the Pandas Preprocessing in parallel and leverage Orca TF Estimator to train a Tensorflow graph model in the same cluster. \n",
    "\n",
    "The system ([Recommendation systems: Principles, methods and evaluation](http://www.sciencedirect.com/science/article/pii/S1110866515000341)) normally prompts the user through the system interface to provide ratings for items in order to construct and improve the model. The accuracy of recommendation depends on the quantity of ratings provided by the user.  \n",
    "\n",
    "NCF([He, 2015](https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf)) leverages a multi-layer perceptrons to learn the userâ€“item interaction function, at the mean time, NCF can express and generalize matrix factorization under its framework. includeMF(Boolean) is provided for users to build a NCF with or without matrix factorization. \n",
    "\n",
    "Data: \n",
    "* The dataset we used is movielens-1M ([link](https://grouplens.org/datasets/movielens/1m/)), which contains 1 million ratings from 6000 users on 4000 movies.  There're 5 levels of rating. We will try classify each (user,movie) pair into 5 classes and evaluate the effect of algortithms using Mean Absolute Error.  \n",
    "  \n",
    "References: \n",
    "* A Keras implementation of Movie Recommendation([notebook](https://github.com/ririw/ririw.github.io/blob/master/assets/Recommending%20movies.ipynb)) from the [blog](http://blog.richardweiss.org/2016/09/25/movie-embeddings.html).\n",
    "* Nerual Collaborative filtering ([He, 2015](https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from bigdl.dataset import base\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import zoo.orca.learn.tf.estimator\n",
    "from zoo.orca.data import SharedValue\n",
    "import zoo.orca.data.pandas\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Download movielens 1M data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_URL = 'http://files.grouplens.org/datasets/movielens/'\n",
    "WHOLE_DATA = 'ml-1m.zip'\n",
    "data_dir='/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file = base.maybe_download(WHOLE_DATA, data_dir, SOURCE_URL + WHOLE_DATA)\n",
    "zip_ref = zipfile.ZipFile(local_file, 'r')\n",
    "extracted_to = os.path.join(data_dir, \"ml-1m\")\n",
    "if not os.path.exists(extracted_to):\n",
    "    print(\"Extracting %s to %s\" % (local_file, data_dir))\n",
    "    zip_ref.extractall(data_dir)\n",
    "    zip_ref.close()\n",
    "rating_files = os.path.join(extracted_to, \"ratings.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Replace \"::\" to \":\" in ratings.dat and save to ratings_new.dat for spark 2.4 read csv support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rating_files = os.path.join(extracted_to, \"ratings_new.dat\")\n",
    "if not os.path.exists(new_rating_files):\n",
    "    fin = open(rating_files, \"rt\")\n",
    "    # output file to write the result to\n",
    "    fout = open(new_rating_files, \"wt\")\n",
    "    # for each line in the input file\n",
    "    for line in fin:\n",
    "        # read replace the string and write to output file\n",
    "        fout.write(line.replace('::', ':'))\n",
    "    # close input and output files\n",
    "    fin.close()\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
