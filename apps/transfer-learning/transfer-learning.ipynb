{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the image transfer learning example, we use a pre-trained Inception_V1 model as image feature transformer and train another linear classifier to solve the dogs-vs-cats classification problem.\n",
    "\n",
    "In this notebook we are going to take a slightly different approach. We will still use a pre-trained Inception_V1 model, but this time we will operate on the pre-trained model to freeze first of a few layers, replace the classifier on the top, then fine tune the whole model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dogs-vs-cats datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the training dataset from https://www.kaggle.com/c/dogs-vs-cats and extract it. \n",
    "\n",
    "The following commands copy about 1100 images of cats and dogs into demo/cats and demo/dogs separately. \n",
    "```shell\n",
    "mkdir -p demo/dogs\n",
    "mkdir -p demo/cats\n",
    "cp train/cat.7* demo/cats\n",
    "cp train/dog.7* demo/dogs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the pre-trained Inception-V1 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the pre-trained Inception-V1 model from [Zoo](https://s3-ap-southeast-1.amazonaws.com/bigdl-models/imageclassification/imagenet/bigdl_inception-v1_imagenet_0.4.0.model) \n",
    " Alternatively, user may also download pre-trained caffe/Tensorflow/keras model. Please refer to programming guide in  [BigDL](https://bigdl-project.github.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding /home/arda/chentao/MyPython/lib/python2.7/site-packages/bigdl/share/lib/bigdl-0.5.0-jar-with-dependencies.jar to BIGDL_JARS\n",
      "Prepending /home/arda/chentao/MyPython/lib/python2.7/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path\n",
      "creating: createDefault\n",
      "creating: createSGD\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from bigdl.nn.criterion import CrossEntropyCriterion\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "\n",
    "from zoo.common.nncontext import *\n",
    "from zoo.feature.image import *\n",
    "from zoo.pipeline.api.keras.layers import Dense, Input, Flatten\n",
    "from zoo.pipeline.api.keras.models import *\n",
    "from zoo.pipeline.api.net import *\n",
    "from zoo.pipeline.nnframes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkConf = SparkConf().setAppName(\"ImageTransferLearningExample\")\n",
    "sc = init_nncontext(sparkConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_path = \"/home/arda/chentao/work/xiaxue/bigdl_inception-v1_imagenet_0.4.0.model\"\n",
    "image_path = \"/home/arda/chentao/work/xiaxue/demo/*/*\"\n",
    "imageDF = NNImageReader.readImages(image_path, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "getName = udf(lambda row:\n",
    "                  re.search(r'(cat|dog)\\.([\\d]*)\\.jpg', row[0], re.IGNORECASE).group(0),\n",
    "                  StringType())\n",
    "getLabel = udf(lambda name: 1.0 if name.startswith('cat') else 2.0, DoubleType())\n",
    "\n",
    "labelDF = imageDF.withColumn(\"name\", getName(col(\"image\"))) \\\n",
    "        .withColumn(\"label\", getLabel(col('name')))\n",
    "(trainingDF, validationDF) = labelDF.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compose a pipeline that includes feature transform, pretrained model and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createRowToImageFeature\n",
      "creating: createImageResize\n",
      "creating: createImageCenterCrop\n",
      "creating: createImageChannelNormalize\n",
      "creating: createImageMatToTensor\n",
      "creating: createImageFeatureToTensor\n",
      "creating: createChainedPreprocessing\n"
     ]
    }
   ],
   "source": [
    "transformer = ChainedPreprocessing(\n",
    "        [RowToImageFeature(), ImageResize(256, 256), ImageCenterCrop(224, 224),\n",
    "         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageFeatureToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = Net.load_bigdl(model_path)\n",
    "# create a new model by remove layers after pool5/drop_7x7_s1\n",
    "model = full_model.new_graph([\"pool5/drop_7x7_s1\"])\n",
    "# freeze layers from input to pool4/3x3_s2 inclusive\n",
    "model.freeze_up_to([\"pool4/3x3_s2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createZooKerasInput\n",
      "creating: createZooKerasFlatten\n",
      "creating: createZooKerasDense\n"
     ]
    }
   ],
   "source": [
    "inputNode = Input(name=\"input\", shape=(3, 224, 224))\n",
    "inception = model.to_keras()(inputNode)\n",
    "flatten = Flatten()(inception)\n",
    "logits = Dense(2)(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createZooKerasModel\n"
     ]
    }
   ],
   "source": [
    "lrModel = Model(inputNode, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createCrossEntropyCriterion\n",
      "creating: createScalarToTensor\n",
      "creating: createFeatureLabelPreprocessing\n",
      "creating: createNNClassifier\n"
     ]
    }
   ],
   "source": [
    "classifier = NNClassifier(lrModel, CrossEntropyCriterion(), transformer) \\\n",
    "        .setLearningRate(0.003).setBatchSize(40).setMaxEpoch(1).setFeaturesCol(\"image\") \\\n",
    "        .setCachingSample(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createToTuple\n",
      "creating: createChainedPreprocessing\n",
      "creating: createTensorToSample\n",
      "creating: createChainedPreprocessing\n"
     ]
    }
   ],
   "source": [
    "catdogModel = pipeline.fit(trainingDF)\n",
    "predictionDF = catdogModel.transform(validationDF).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = predictionDF.filter(\"label=prediction\").count()\n",
    "overall = predictionDF.count()\n",
    "accuracy = correct * 1.0 / overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0372093 \n"
     ]
    }
   ],
   "source": [
    "print(\"Test Error = %g \" % (1.0 - accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
