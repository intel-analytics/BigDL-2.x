{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Variational Autoencoder and Deep Feature Loss to Generate Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the \"Using Variational Autoencoder to Generate Faces\" example, we see that using VAE, we can generate realistic human faces, but the generated image is a little blury. Though, you can continue to tuning the hyper paramters or using more data to get a better result, in this example, we adopted the approach in [this paper](https://arxiv.org/abs/1610.00291). That is, instead of using pixel-by-pixel loss of between the original images and the generated images, we use the feature map generated by a pre-trained CNN network to define a feature perceptual loss. As you will see, the generated images will become more vivid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigdl.nn.layer import *\n",
    "from bigdl.nn.criterion import *\n",
    "from bigdl.optim.optimizer import *\n",
    "from bigdl.dataset import mnist\n",
    "import datetime as dt\n",
    "from bigdl.util.common import *\n",
    "from glob import glob\n",
    "import os\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "image_size = 148\n",
    "Z_DIM = 100\n",
    "ENCODER_FILTER_NUM = 32\n",
    "DATA_PATH = \"/tmp/celeba/img_align_celeba\"\n",
    "\n",
    "init_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are uing the same model as \"Using Variational Autoencoder to Generate Faces\" example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_lrelu(in_channels, out_channles, kw=4, kh=4, sw=2, sh=2, pw=-1, ph=-1):\n",
    "    model = Sequential()\n",
    "    model.add(SpatialConvolution(in_channels, out_channles, kw, kh, sw, sh, pw, ph))\n",
    "    model.add(SpatialBatchNormalization(out_channles))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    return model\n",
    "\n",
    "def deconv_bn_lrelu(in_channels, out_channles, kw=4, kh=4, sw=2, sh=2, pw=0, ph=0):\n",
    "    model = Sequential()\n",
    "    model.add(SpatialFullConvolution(in_channels, out_channles, kw, kh, sw, sh, pw, ph))\n",
    "    model.add(SpatialBatchNormalization(out_channles))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder_cnn():\n",
    "    input0 = Input()\n",
    "    \n",
    "    #CONV\n",
    "    conv1 = conv_bn_lrelu(3, 32)(input0) # 32 * 32 * 32\n",
    "    conv2 = conv_bn_lrelu(32, 64)(conv1) # 16 * 16 * 64\n",
    "    conv3 = conv_bn_lrelu(64, 128)(conv2) # 8 * 8 * 128\n",
    "    conv4 = conv_bn_lrelu(128, 256)(conv3) # 4 * 4 * 256\n",
    "    view = View([4*4*256])(conv4)\n",
    "    \n",
    "    # fully connected to generate mean and log-variance\n",
    "    mean = Linear(4*4*256, Z_DIM)(view)\n",
    "    log_variance = Linear(4*4*256, Z_DIM)(view)\n",
    "    \n",
    "    model = Model([input0], [mean, log_variance])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder_cnn():\n",
    "    input0 = Input()\n",
    "    \n",
    "    linear = Linear(Z_DIM, 4*4*256)(input0)\n",
    "    reshape = Reshape([256, 4, 4])(linear)\n",
    "    bn = SpatialBatchNormalization(256)(reshape)\n",
    "    \n",
    "    # upsampling\n",
    "    deconv1 = deconv_bn_lrelu(256, 128, pw=1, ph=1)(bn) # 8 * 8 * 128\n",
    "    deconv2 = deconv_bn_lrelu(128, 64, pw=1, ph=1)(deconv1) # 16 * 16 * 64\n",
    "    deconv3 = deconv_bn_lrelu(64, 32, pw=1, ph=1)(deconv2) # 32 * 32 * 32\n",
    "    deconv4 = deconv_bn_lrelu(32, 3, pw=1, ph=1)(deconv3) # 64 * 64 * 3\n",
    "    output = Tanh()(deconv4)\n",
    "    \n",
    "    model = Model([input0], [output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autoencoder_cnn():\n",
    "    input0 = Input()\n",
    "    encoder = get_encoder_cnn()(input0)\n",
    "    sampler = GaussianSampler()(encoder)\n",
    "    \n",
    "    decoder_model = get_decoder_cnn()\n",
    "    decoder = decoder_model(sampler)\n",
    "    \n",
    "    model = Model([input0], [encoder, decoder])\n",
    "    return model, decoder_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pre-trained CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg():\n",
    "    # we use the vgg16 model, it should work on other popular CNN models\n",
    "    # You can download them here (link TO BE ADDED)\n",
    "    vgg_whole = Model.from_jvalue(Model.loadModel(\"/tmp/bigdl/vgg16.bigdl\").value)\n",
    "\n",
    "    # we only use one feature map here for the sake of simlicity and efficiency\n",
    "    outputs = [vgg_whole.node(name) for name in [\"relu1_2\"]]\n",
    "    inputs = [vgg_whole.node(name) for name in [\"data\"]]\n",
    "    \n",
    "    outputs[0].remove_next_edges()\n",
    "\n",
    "    vgg_light = Model(inputs, outputs).freeze()\n",
    "    \n",
    "    return vgg_light\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createModel\n"
     ]
    }
   ],
   "source": [
    "vgg = get_vgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createInput\n",
      "creating: createInput\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createLeakyReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createLeakyReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createLeakyReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createLeakyReLU\n",
      "creating: createView\n",
      "creating: createLinear\n",
      "creating: createLinear\n",
      "creating: createModel\n",
      "creating: createGaussianSampler\n",
      "creating: createInput\n",
      "creating: createLinear\n",
      "creating: createReshape\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createSequential\n",
      "creating: createSpatialFullConvolution\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createLeakyReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialFullConvolution\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createLeakyReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialFullConvolution\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createLeakyReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialFullConvolution\n",
      "creating: createSpatialBatchNormalization\n",
      "creating: createLeakyReLU\n",
      "creating: createTanh\n",
      "creating: createModel\n",
      "creating: createModel\n"
     ]
    }
   ],
   "source": [
    "model, decoder = get_autoencoder_cnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    data_files = glob(os.path.join(DATA_PATH, \"*.jpg\"))\n",
    "    \n",
    "    rdd_train_images = sc.parallelize(data_files[:100000]) \\\n",
    "                              .map(lambda path: get_image(path, image_size).transpose(2, 0, 1))\n",
    "\n",
    "    rdd_train_sample = rdd_train_images.map(lambda img: Sample.from_ndarray(img, [np.array(0.0), img]))\n",
    "    return rdd_train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Training Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createParallelCriterion\n",
      "creating: createKLDCriterion\n",
      "creating: createMSECriterion\n",
      "creating: createTransformerCriterion\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bigdl.nn.criterion.ParallelCriterion at 0x7f66f0a61610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = ParallelCriterion()\n",
    "criterion.add(KLDCriterion(), 0.005) # You may want to twick this parameter\n",
    "criterion.add(TransformerCriterion(MSECriterion(), vgg, vgg), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createAdam\n",
      "creating: createMaxEpoch\n",
      "creating: createDistriOptimizer\n",
      "creating: createTrainSummary\n",
      "saving logs to  vae-20171225-235919\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "\n",
    "# Create an Optimizer\n",
    "optimizer = Optimizer(\n",
    "    model=model,\n",
    "    training_rdd=train_data,\n",
    "    criterion=criterion,\n",
    "    optim_method=Adam(0.0005),\n",
    "    end_trigger=MaxEpoch(15),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "\n",
    "app_name='vae-'+dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_summary = TrainSummary(log_dir='/tmp/vae',\n",
    "                                     app_name=app_name)\n",
    "\n",
    "\n",
    "optimizer.set_train_summary(train_summary)\n",
    "\n",
    "print \"saving logs to \",app_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spin Up the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redire_spark_logs()\n",
    "show_bigdl_info_logs()\n",
    "trained_model = optimizer.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.array(train_summary.read_scalar(\"Loss\"))\n",
    "\n",
    "plt.figure(figsize = (12,12))\n",
    "plt.plot(loss[:,0],loss[:,1],label='loss')\n",
    "plt.xlim(0,loss.shape[0]+10)\n",
    "plt.grid(True)\n",
    "plt.title(\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sample Some Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "plt.figure(figsize=(10, 80))\n",
    "img = np.column_stack([decoder.forward(np.random.randn(1, 100)).reshape(3, 64,64).transpose(1, 2, 0) for s in range(8)])\n",
    "imshow(inverse_transform(img))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
