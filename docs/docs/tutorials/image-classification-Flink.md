# Real-time image classification using Analytics Zoo and Flink

- [Getting started this tutorial](#Getting-started-this-tutorial)  
  - [Summary](#Summary)
  - [Preparation](#Preparation)
- [Loading and preprocessing images](#Loading-and-preprocessing-images)  
  - [Knowing about dataset](#Knowing-about-dataset)
  - [Preprocessing dataset](#preprocessing-dataset)
- [Starting the image classification program on Flink ](#Starting-the-image-classification-program-on-Flink)  
  - [Obtaining an execution environment](#Obtaining-an-execution-environment)  
  - [Creating DataStream](#creating-datastream)  
  - [Executing transformation functions](#Executing-transformation-functions)  
    - [Defining an Analytics Zoo Inference Model](#Defining-an-Analytics-Zoo-Inference-Model)
    - [Specifying MapFunction](#Specifying-MapFunction)
    - [DataStream map transformation](#DataStream-map-transformation)
  - [Triggering the program execution](#triggering-the-program-execution)    
  - [Collecting final results](#collecting-final-results)   
- [Running the Flink program on a local machine or a cluster](#running-the-flink-program-on-a-local-machine-or-a-cluster)
  - [Building the project](#Building-the-project)
  - [Configuring and starting Flink](#Configuring-and-starting-Flink)
  - [Running the example](#Running-the-example)

## Getting started this tutorial

### Summary

This is the real-time image classification on Apache Flink streaming. Images extracted from ImageNet database will be predicted with pre-trained ResNet-50 model which is loaded by Analytics Zoo Inference model.

ImageNet is a large-scale database designed for use in visual object detection research. It has more than 14 million images among more than 20,000 categories, such as keyboard, mouse, pencil, and animals.

ResNet is one of the powerful pretrained deep neural networks which has achieved the first place on ImageNet recognition. ResNet-50 is 50 layers deep that is trained on a million images from the ImageNet database and can classify images into 1000 object categories. The network has an image input size of 224-by-224.

Analytics Zoo Inference Model package is aiming to provide high-level APIs to speed-up development.  It provides easy-to-use APIs for loading and prediction with deep learning models of Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR).

Apache Flink is a powerful stream processing framework that supports batch processing, data streaming programs and running in common cluster environment. 

Let's get started this tutorial. We will use an example to introduce how to load ResNet50 model as Analytics Zoo Inference Model TFNet for the real-time image prediction on Flink streaming. See the whole program [here](https://github.com/intel-analytics/analytics-zoo/tree/master/apps/model-inference-examples/model-inference-flink). 

### Preparation

- **Environment preparation**

Make sure JDK 1.8, Scala 2.11/2.12, Flink 1.8.1, and Maven are installed. 

- **Model preparation**

The pre-trained ResNet50 saved model can be generated by the [script](). 

- **Building a project directory and installing Analytics Zoo** 

The example project contains: a POM file which is used by Maven to build the project; the source directory, which is `src/main/scala`.

Follow the instructions [here](https://analytics-zoo.github.io/master/#ScalaUserGuide/install/) to install analytics-zoo for Scala project. Specify dependencies in the POM file. See the example [pom.xml](https://github.com/intel-analytics/analytics-zoo/blob/master/apps/model-inference-examples/model-inference-flink/pom.xml) which is setting the required dependencies and configuration details of Analytics Zoo, Flink and scala for this project.

If you import the example project in the IDE(eg: IDEA), select **New - Project** from existing source, look through the example project directory and click OK, then select open as project in the window pop out next, using maven to build up the project.

## Loading and preprocessing images

#### Knowing about dataset

The raw images in **ImageNet** are various sizes.  Let us show two of the predicting images.

<img src="../../zoo/src/test/resources/imagenet/n02110063/n02110063_15462.JPEG" width="180">       
<img src="../../zoo/src/test/resources/imagenet/n04370456/n04370456_5753.JPEG" width="180">

#### Preprocessing dataset

Pre-process data as you need. ResNet-50 network has the image input of 224 by 224. As the inference model requires input of `JList[JList[JTensor]]`, the final output will be processed to that type. 

In this sample, `trait ImageProcessing` is prepared to provide approaches to convert format, resize and normalize. These methods are defined [here](https://github.com/intel-analytics/analytics-zoo/blob/master/apps/model-inference-examples/model-inference-flink/src/main/scala/com/intel/analytics/zoo/apps/model/inference/flink/Resnet50ImageClassification/ImageProcessing.scala). 

First, let us load images from the image folder.

```scala
// load images from folder, and hold images as a list
val fileList = new File(imageDir).listFiles.toList
```

A  [ImageProcessor class]() is created to apply methods from `trait ImageProcessing` to implement image pre-processing. 

```scala
class ImageProcessor extends ImageProcessing {
    def processForResNetTFNet(bytes: Array[Byte], cropWidth: Int, cropHeight: Int) = {
    // convert Array[byte] to OpenCVMat   
    val imageMat = byteArrayToMat(bytes)
    // do a center crop by resizing a square
    val imageCent = centerCrop(imageMat, cropWidth, cropHeight)
    // convert to array
    val imageArray = matToArray(imageCent)
    imageArray
  }
}
```

Each input image read from image folder is supposed to be converted as below, where each image read as Array[Byte]  and convert to the required type.

```scala
val inputImages = fileList.map(file => {
      // read image as Array[Byte]
      val imageBytes = FileUtils.readFileToByteArray(file)
      // execute image processing with ImageProcessor
      val imageProcess = new ImageProcessor
      val res = imageProcess.processForResNetTFNet(imageBytes, 224, 224)
      // convert to List[List[JTensor]] input
      val input = new JTensor(res, Array(1, 224, 224, 3))
      List(util.Arrays.asList(input)).asJava
    })
```

## Starting the image classification program on Flink 

### Obtaining an execution environment

The first step is to create an execution environment. The `StreamExecutionEnvironment` is the context in which a streaming program is executed. `getExecutionEnvironment` is the typical function creating an environment to execute your program when the program is invoked on your local machine or a cluster.

```scala
val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment
```

### Creating DataStream

`StreamExecutionEnvironment` provides several stream sources function. As we use `List` to hold the input images, we can create a DataStream from a collection using `fromCollection()` method.

```scala
// dataStream
val dataStream: DataStream[JList[JList[JTensor]]] = env.fromCollection(inputImages)
```

### Executing transformation functions

#### Defining an Analytics Zoo Inference Model

Analytics Zoo provides Inference Model package for speeding up prediction with deep learning models of Analytics Zoo, Caffe, Tensorflow and OpenVINO Intermediate Representation(IR). You may see [here](https://github.com/intel-analytics/analytics-zoo/blob/master/zoo/src/main/scala/com/intel/analytics/zoo/pipeline/inference/InferenceModel.scala) for more details of Inference Model APIs.

Define a class extended Analytics Zoo `InferenceModel`. We use the pre-trained saved model of RestNet50 and load it as TFNet in this example. The saved model is generated from [script](). You can also extract a ready saved model [here]().

Let's define the input parameters of the class:

- **concurrentNum**-the number of requests a model can accept concurrently.
- **savedModelBytes**-the bytes of the model
- **inputs**-the inputs of saved model
- **outputs**-the outputs of saved model
- **intraOpParallelismThreads**- the num of intraOpParallelismThreads
- **interOpParallelismThreads**- the num of interOpParallelismThreads
- **usePerSessionThreads**- whether to perSessionThreads

```scala
// concurrentNum
var concurrentNum = 1

// to obtain savedModelBytes for model streaming on Flink, there are several steps
// abstract path of the saved model tar
var savedModelPath: String = "/path/to/model.tar.gz"

// length of the file in bytes
val fileSize = new File(savedModelPath).length()

// Create a file inputStream 
val inputStream = new FileInputStream(savedModelPath)

// convert fileSize to Array[Byte]
val savedModelBytes = new Array[Byte](fileSize.toInt)
inputStream.read(savedModelBytes)

// inputs
var inputs = Array("resnet50_input:0")

// outputs 
var outputs = Array("resnet50/fc1000/Softmax:0")

// intraOpParallelismThreads
var intraOpParallelismThreads = 1

// interOpParallelismThreads
var interOpParallelismThreads = 1

// usePerSessionThreads
var usePerSessionThreads = true
```

Let's define a `Resnet50InferenceModel` class to extend analytics zoo `InferenceModel`.

```scala
class Rennet50TFNetInferenceModel(var concurrentNum: Int = 1, savedModelBytes: Array[Byte], inputs: Array[String], outputs: Array[String], intraOpParallelismThreads: Int, interOpParallelismThreads: Int, usePerSessionThreads: Boolean) 
extends InferenceModel(concurrentNum) with Serializable {
    
  // load the TF model as TFNet  
  doLoadTF(savedModelBytes, inputs, outputs, intraOpParallelismThreads, interOpParallelismThreads, usePerSessionThreads)
    
}
```

#### Specifying MapFunction

Define a class extends `RichMapFunction`. Three main methods of rich function in this example are open, close and map. `open()` is initialization method. `close()` is called after the last call to the main working methods. `map()` is the user-defined function, mapping an element from the input data set and to one exact element, ie, `JList[JList[JTensor]]`.

```scala
class ModelPredictionMapFunctionTFNet(savedModelBytes: Array[Byte], inputs: Array[String], outputs: Array[String], intraOpParallelismThreads: Int, interOpParallelismThreads: Int, usePerSessionThreads: Boolean) 
extends RichMapFunction[JList[JList[JTensor]], Int] {
  var resnet50InferenceModel: Rennet50TFNetInferenceModel = _

  // open
  override def open(parameters: Configuration): Unit = {
    resnet50InferenceModel = new Rennet50TFNetInferenceModel(1, savedModelBytes, inputs, outputs, intraOpParallelismThreads, interOpParallelismThreads, usePerSessionThreads)
  }

  // close
  override def close(): Unit = {
    resnet50InferenceModel.doRelease()
  }

  // define map function with InferenceModel doPredict function
  // return predicted classes index
  override def map(in: JList[JList[JTensor]]): (Int) = {
    val outputData = resnet50InferenceModel.doPredict(in).get(0).get(0).getData
    val max: Float = outputData.max
    val index = outputData.indexOf(max)
    (index)
  }
}
```

#### DataStream map transformation

Pass the `RichMapFunctionn`  to a `map` transformation.

```scala
val resultStream = dataStream.map(new ModelPredictionMapFunctionTFNet(savedModelBytes, inputs, outputs, intraOpParallelismThreads, interOpParallelismThreads, usePerSessionThreads))
```

### Triggering the program execution

The program is actually executed only when calling `execute()` on the `StreamExecutionEnvironment`. Whether the program is executed locally or submitted on a cluster depends on the type of execution environment.

```scala
env.execute()
```

### Collecting final results

Finally, iterate over the elements of the DataStream. 

```scala
val results = DataStreamUtils.collect(resultStream.javaStream).asScala
results.foreach((i) => println(labels(i)))
```

At this step, we complete the whole program. Let's start how to run the example on a cluster.

## Running the Flink program on a local machine or a cluster

- ##### Building the project

Build the project using Maven because we need the jar file for running on the cluster. Go to the root directory of your inference flink project and execute the mvn clean package command, which prepares the jar file for your model inference flink program:

```scala
mvn clean package
```

The resulting jar file will be in the target subfolder: target/model-inference-flink-0.1.0-SNAPSHOT-jar-with-dependencies.jar. Weâ€™ll use this later.

- ##### Configuring and starting Flink

Before start a flink cluster, edit /conf/flink-conf.yaml to set heap size or the number of task slots as you need, ie, `jobmanager.heap.size: 10g`, `taskmanager.numberOfTaskSlots: 2` 

You may start a flink cluster if there is no running one. Go to the location where you installed fink :

```scala
./bin/start-cluster.sh
```

Check the Dispatcher's web frontend at [http://localhost:8081](http://localhost:8081/) and make sure everything is up and running. To stop Flink when you're done type:

```scala
./bin/stop-cluster.sh
```

- ##### Running the Example

All are ready! Let's run the following command with arguments to submit the Flink program. Change parameter settings as you need.

```shell
${FLINK_HOME}/bin/flink run \
    -m localhost:8081 -p 2 \
    -c com.intel.analytics.zoo.apps.model.inference.flink.Resnet50ImageClassification.ImageClassificationTFNetStreaming  \
    ${ANALYTICS_ZOO_HOME}/apps/model-inference-examples/model-inference-flink/target/model-inference-flink-0.1.0-SNAPSHOT-jar-with-dependencies.jar
```

The output of that command should look similar as below  if everything went according to plan.  It shows the prediction result.

```
Siberian husky
sweatshirt
Program execution finished
Job with JobID 22f9c394f0df3bcb4135a1c7675daa7c has finished.
Job Runtime: 11285 ms
```

#### Wrapping up

we have reached the end of the tutorial. In this tutorial, you have learned how to use Analytics Zoo Inference Model for image classification on streaming. You explore to create the `InferenceModel` class for loading and prediction with a deep learning model. With that, you defined your own `RichMapFunction` and started with the prediction on Flink streaming.

What goes for next? You could take practice. Load the data and model you need to see what speedup you get.
