{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "super_resolution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7XtJ6cHVgtEgwC9CcdFXA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgwhat/analytics-zoo/blob/colab-examples/docs/docs/colab-notebook/orca/examples/super_resolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9l8_mtY64CL"
      },
      "source": [
        "#\n",
        "# Copyright 2018 Analytics Zoo Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "# This example trains a super-resolution network on the BSD300 dataset,\n",
        "# using crops from the 200 training images, and evaluating on crops of the 100 test images,\n",
        "# and is adapted from\n",
        "# https://github.com/pytorch/examples/tree/master/super_resolution\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ResW0PSY4xWC"
      },
      "source": [
        "## **Environment Preparation**\n",
        "\n",
        "**Install Java 8**\n",
        "\n",
        "Run the cell on the **Google Colab** to install jdk 1.8.\n",
        "\n",
        "**Note:** if you run this notebook on your computer, root permission is required when running the cell to install Java 8. (You may ignore this cell if Java 8 has already been set up in your computer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0p4mAbe0iH4"
      },
      "source": [
        "# Install jdk8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "# Set environment variable JAVA_HOME.\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-dVmMas8KfK"
      },
      "source": [
        "**Install Analytics Zoo**\n",
        "\n",
        "[Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) is needed to prepare the Python environment for running this example. \n",
        "\n",
        "**Note**: The following code cell is specific for setting up conda environment on Colab; for general conda installation, please refer to the [install guide](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69suYs9K0kiu"
      },
      "source": [
        "import sys\n",
        "\n",
        "# Get current python version\n",
        "version_info = sys.version_info\n",
        "python_version = f\"{version_info.major}.{version_info.minor}.{version_info.micro}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JczTAk5E0nW2"
      },
      "source": [
        "# Install Miniconda\n",
        "!wget https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "# Update Conda\n",
        "!conda install --channel defaults conda python=$python_version --yes\n",
        "!conda update --channel defaults --all --yes\n",
        "\n",
        "# Append to the sys.path\n",
        "_ = (sys.path\n",
        "        .append(f\"/usr/local/lib/python{version_info.major}.{version_info.minor}/site-packages\"))\n",
        "\n",
        "os.environ['PYTHONHOME']=\"/usr/local\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaopMtV98hB-"
      },
      "source": [
        "You can install the latest pre-release version using `pip install --pre  analytics-zoo`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUGTC8lT07ZE"
      },
      "source": [
        "# Install latest pre-release version of Analytics Zoo \n",
        "# For torch_distributed backend\n",
        "!pip install --pre --upgrade analytics-zoo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6cZpzM4hPIP"
      },
      "source": [
        "# Install torchvision by conda\n",
        "!pip install tqdm\n",
        "!conda install pytorch torchvision cpuonly -c pytorch -y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxSHPvimz9_G"
      },
      "source": [
        "# Install required dependencies\n",
        "!pip install pillow\n",
        "!pip install jep==3.9.0\n",
        "!pip install cloudpickle\n",
        "!pip install tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mo8uojl9rQN"
      },
      "source": [
        "## **Distributed Pytorch using Orca APIs**\n",
        "\n",
        "In this guide we will describe how to scale out PyTorch programs using Orca in 5 simple steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-mCzxMaN-Fc"
      },
      "source": [
        "#import necessary libraries and modules\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "\n",
        "import urllib\n",
        "import tarfile\n",
        "from math import log10\n",
        "from PIL import Image\n",
        "from os import makedirs, remove, listdir\n",
        "from os.path import exists, join, basename\n",
        "\n",
        "from zoo.orca import init_orca_context, stop_orca_context\n",
        "from zoo.orca import OrcaContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrFNoK26_Dzp"
      },
      "source": [
        "### **Step 1: Init Orca Context**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXSqnMoQ24PO"
      },
      "source": [
        "# recommended to set it to True when running Analytics Zoo in Jupyter notebook. \n",
        "OrcaContext.log_output = True # (this will display terminal's stdout and stderr in the Jupyter notebook).\n",
        "\n",
        "cluster_mode = \"local\"\n",
        "\n",
        "if cluster_mode == \"local\":\n",
        "    init_orca_context(cores=1, memory=\"2g\") # run in local mode\n",
        "elif cluster_mode == \"k8s\":\n",
        "    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=4) # run on K8s cluster\n",
        "elif cluster_mode == \"yarn\":\n",
        "    init_orca_context(\n",
        "        cluster_mode=\"yarn-client\", cores=4, num_nodes=2, memory=\"2g\",\n",
        "        driver_memory=\"10g\", driver_cores=1,\n",
        "        conf={\"spark.rpc.message.maxSize\": \"1024\",\n",
        "              \"spark.task.maxFailures\": \"1\",\n",
        "              \"spark.driver.extraJavaOptions\": \"-Dbigdl.failure.retryTimes=1\"}) # run on Hadoop YARN cluster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUOk_SJRSfbD"
      },
      "source": [
        "This is the only place where you need to specify local or distributed mode. View [Orca Context](https://analytics-zoo.readthedocs.io/en/latest/doc/Orca/Overview/orca-context.html) for more details.\n",
        "\n",
        "**Note**: You should export HADOOP_CONF_DIR=/path/to/hadoop/conf/dir when you run on Hadoop YARN cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6q-5q_H_ZFc"
      },
      "source": [
        "### **Step 2: Define the Model**\n",
        "You may define your model, loss and optimizer in the same way as in any standard (single node) PyTorch program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3ANE_oF2VxX"
      },
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, upscale_factor):\n",
        "        super(Net, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
        "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.pixel_shuffle(self.conv4(x))\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv4.weight)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "net = Net(upscale_factor=3)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQrtqGANLFSw"
      },
      "source": [
        "# training parameters\n",
        "criterion = nn.MSELoss()\n",
        "model_dir = \"models\"\n",
        "\n",
        "epochs = 1\n",
        "thread = 4\n",
        "batch_size = 64\n",
        "test_batch_size = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR_6N61wADCI"
      },
      "source": [
        "### **Step 3: Define Train Dataset**\n",
        "\n",
        "**Prepare Dataset**\n",
        "\n",
        "This is an example using the efficient sub-pixel convolution layer to train on BSDS3000 dataset, using crops from the 200 training images, and evaluating on crops of the 100 test images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdk4BfMygZWG"
      },
      "source": [
        "# download dataset\n",
        "def download_report(count, block_size, total_size):\n",
        "    downloaded = count * block_size\n",
        "    percent = 100. * downloaded / total_size\n",
        "    percent = min(100, percent)\n",
        "    print('downloaded %d, %.2f%% completed' % (downloaded, percent))\n",
        "\n",
        "def download_bsd300(dest=\"./dataset\"):\n",
        "    output_image_dir = join(dest, \"BSDS300/images\")\n",
        "\n",
        "    if not exists(output_image_dir):\n",
        "        makedirs(dest)\n",
        "        url = \"http://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300-images.tgz\"\n",
        "        print(\"downloading url \", url)\n",
        "\n",
        "        file_path = join(dest, basename(url))\n",
        "        urllib.request.urlretrieve(url, file_path, download_report)\n",
        "\n",
        "        print(\"Extracting data\")\n",
        "        with tarfile.open(file_path) as tar:\n",
        "            for item in tar:\n",
        "                tar.extract(item, dest)\n",
        "        remove(file_path)\n",
        "    return output_image_dir\n",
        "\n",
        "# the traning dataset can only be image\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfEcaWUk9c0j"
      },
      "source": [
        "Get training image data from download path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_qJKcyPfhR3"
      },
      "source": [
        "class DatasetFromFolder(data.Dataset):\n",
        "    def __init__(self, image_dir, input_transform=None, target_transform=None):\n",
        "        super(DatasetFromFolder, self).__init__()\n",
        "        self.image_filenames = [join(image_dir, x)\n",
        "                                for x in listdir(image_dir) if is_image_file(x)]\n",
        "        self.input_transform = input_transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        input = load_img(self.image_filenames[index])\n",
        "        target = input.copy()\n",
        "        if self.input_transform:\n",
        "            input = self.input_transform(input)\n",
        "        if self.target_transform:\n",
        "            target = self.target_transform(target)\n",
        "        return input, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3ZUMX4i-MoS"
      },
      "source": [
        "Preprocess the image dataset and transfer PIL.Image to Tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu6f9MajflwR"
      },
      "source": [
        "from torchvision.transforms import Compose, CenterCrop, ToTensor, Resize\n",
        "\n",
        "def load_img(filepath):\n",
        "    img = Image.open(filepath).convert('YCbCr')\n",
        "    y, _, _ = img.split()\n",
        "    return y\n",
        "\n",
        "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
        "    return crop_size - (crop_size % upscale_factor)\n",
        "\n",
        "def input_transform(crop_size, upscale_factor):\n",
        "    return Compose([\n",
        "        CenterCrop(crop_size),\n",
        "        Resize(crop_size // upscale_factor),\n",
        "        ToTensor(),\n",
        "    ])\n",
        "\n",
        "def target_transform(crop_size):\n",
        "    return Compose([\n",
        "        CenterCrop(crop_size),\n",
        "        ToTensor(),\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VhXqp3q9_cr"
      },
      "source": [
        "You can define the train and test dataloader using standarad `torch.utils.data.DataLoader` and put into dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFKdKOHofWna"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def get_training_set(upscale_factor):\n",
        "  root_dir = download_bsd300()\n",
        "  train_dir = join(root_dir, \"train\")\n",
        "  crop_size = calculate_valid_crop_size(256, upscale_factor)\n",
        "  return DatasetFromFolder(train_dir,\n",
        "                           input_transform=input_transform(crop_size, upscale_factor),\n",
        "                           target_transform=target_transform(crop_size))\n",
        "\n",
        "train_set = get_training_set(3)\n",
        "train_loader = DataLoader(dataset=train_set,\n",
        "                                  batch_size=batch_size,\n",
        "                                  num_workers=thread,\n",
        "                                  shuffle=True)\n",
        "\n",
        "def get_test_set(upscale_factor):\n",
        "  root_dir = download_bsd300()\n",
        "  test_dir = join(root_dir, \"test\")\n",
        "  crop_size = calculate_valid_crop_size(256, upscale_factor)\n",
        "  return DatasetFromFolder(test_dir,\n",
        "                           input_transform=input_transform(crop_size, upscale_factor),\n",
        "                           target_transform=target_transform(crop_size))\n",
        "\n",
        "test_set = get_test_set(3)\n",
        "test_loader = DataLoader(dataset=test_set,\n",
        "                                 batch_size=batch_size,\n",
        "                                 num_workers=thread,\n",
        "                                 shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKvWhWLrDYPp"
      },
      "source": [
        "### **Step 4: Fit with Orca Estimator**\n",
        "\n",
        "First, Create an Estimator and set its backend to `bigdl`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1C5_31C4q_y"
      },
      "source": [
        "from zoo.orca.learn.pytorch import Estimator\n",
        "from zoo.orca.learn.metrics import MSE\n",
        "from zoo.orca.learn.trigger import EveryEpoch\n",
        "\n",
        "estimator = Estimator.from_torch(\n",
        "        model=net,\n",
        "        optimizer=optimizer,\n",
        "        loss=criterion,\n",
        "        model_dir=model_dir,\n",
        "        metrics=[MSE()],\n",
        "        backend=\"bigdl\"\n",
        "    )\n",
        "\n",
        "# the path of the directory where to save the log files to be parsed by TensorBoard\n",
        "tensorboard_dir = \"runs\"\n",
        "# \"bigdl\" is the application name for tensorboard to save training and validation results under log path\n",
        "estimator.set_tensorboard(tensorboard_dir, \"bigdl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8QZ2RzQYiUk"
      },
      "source": [
        "Next, fit using the Estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL9NjhT1d7pP"
      },
      "source": [
        "estimator.fit(data=train_loader, epochs=epochs, validation_data=test_loader, checkpoint_trigger=EveryEpoch())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpfZGf7DwTJt"
      },
      "source": [
        "Finally, evaluate using the Estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPkOwML8d9ee"
      },
      "source": [
        "val_stats = estimator.evaluate(data=test_loader)\n",
        "print(\"Validation stats: {}\".format(val_stats))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj0tn6pMYJiA"
      },
      "source": [
        "The MSE of this model has reached 0.18."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDBJ-J5XeDbl"
      },
      "source": [
        "# Stop orca context when your program finishes\n",
        "stop_orca_context()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OBlnkPjM80S"
      },
      "source": [
        "### **Step 5: Visualization by Tensorboard**\n",
        "\n",
        "TensorBoard is a visualization toolkit for machine learning experimentation. TensorBoard allows tracking and visualizing metrics such as loss and accuracy, visualizing the model graph, viewing histograms, displaying images and much more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lNnhkX68cqW"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYAGL4Mg0Wzv"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# helper function to show an image\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adXtrlX61ayB"
      },
      "source": [
        "A brief overview of the dashboards shown (tabs in top navigation bar):\n",
        "\n",
        "* The **SCALARS** dashboard shows how the loss and metrics change with every epoch. You can use it to also track training speed, learning rate, and other scalar values.\n",
        "* The **IMAGES** dashboard can  be extremely helpful to sample and examine your input data, or to visualize layer weights and generated tensors. \n",
        "* The **GRAPHS** dashboard helps you visualize your model. In this case, the graph of layers is shown which can help you ensure it is built correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPUgw6U6HS3v"
      },
      "source": [
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "tensorboard_dir = \"runs\"\n",
        "writer = SummaryWriter(tensorboard_dir + '/bigdl/train')\n",
        "\n",
        "# plot some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n",
        "\n",
        "# write to tensorboard\n",
        "writer.add_image('images', img_grid)\n",
        "\n",
        "# inspect the model using tensorboard\n",
        "writer.add_graph(net, images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSctDHMnxRue"
      },
      "source": [
        "If you do not need the summary writer anymore, call close() method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP_5AP090cP1"
      },
      "source": [
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndEszjjuw6HF"
      },
      "source": [
        "Start TensorBoard, specifying the root log directory you used above. \n",
        "Argument ``logdir`` points to directory where TensorBoard will look to find \n",
        "event files that it can display. TensorBoard will recursively walk \n",
        "the directory structure rooted at logdir, looking for .*tfevents.* files.\n",
        "This dashboard shows how the loss and accuracy change with every iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyI5lrXoMw9K"
      },
      "source": [
        "%tensorboard --logdir \"/content/runs/bigdl/train\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}