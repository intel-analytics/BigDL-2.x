{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/intel-analytics/analytics-zoo/blob/master/docs/docs/colab-notebook/orca/quickstart/pytorch_lenet_mnist_data_creator_func.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pO3ksbTR18JZ"
   },
   "source": [
    "##### Copyright 2018 Analytics Zoo Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HZJ3OR71u23"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNTssjdw2Bpi"
   },
   "source": [
    "## **Environment Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOosIv3t2Fhp"
   },
   "source": [
    "**Install Java 8**\n",
    "\n",
    "Run the cell on the **Google Colab** to install jdk 1.8.\n",
    "\n",
    "**Note:** if you run this notebook on your computer, root permission is required when running the cell to install Java 8. (You may ignore this cell if Java 8 has already been set up in your computer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBs-RL5p2Ia2"
   },
   "outputs": [],
   "source": [
    "# Install jdk8\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "import os\n",
    "# Set environment variable JAVA_HOME.\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
    "!java -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS20JSbY2LCJ"
   },
   "source": [
    "**Install Analytics Zoo**\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5C1GYEhGIlWu"
   },
   "source": [
    "[Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) is needed to prepare the Python environment for running this example. \n",
    "\n",
    "**Note**: The following code cell is specific for setting up conda environment on Colab; for general conda installation, please refer to the [install guide](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Get current python version\n",
    "version_info = sys.version_info\n",
    "python_version = f\"{version_info.major}.{version_info.minor}.{version_info.micro}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wouustbSJS2r"
   },
   "outputs": [],
   "source": [
    "# Install Miniconda\n",
    "!wget https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
    "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
    "!./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
    "\n",
    "# Update Conda\n",
    "!conda install --channel defaults conda python=$python_version --yes\n",
    "!conda update --channel defaults --all --yes\n",
    "\n",
    "# Append to the sys.path\n",
    "_ = (sys.path\n",
    "        .append(f\"/usr/local/lib/python{version_info.major}.{version_info.minor}/site-packages\"))\n",
    "\n",
    "os.environ['PYTHONHOME']=\"/usr/local\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LOrK0lQHhrh"
   },
   "source": [
    "You can install the latest pre-release version using `pip install --pre  analytics-zoo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8lgWGhG2Oij"
   },
   "outputs": [],
   "source": [
    "# Install latest pre-release version of Analytics Zoo \n",
    "# Installing Analytics Zoo from pip will automatically install pyspark, bigdl, and their dependencies.\n",
    "!pip install --pre analytics-zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3EFkPl4I2RJG"
   },
   "outputs": [],
   "source": [
    "# Install python dependencies\n",
    "!pip install torch==1.7.1 torchvision==0.8.2\n",
    "!pip install six cloudpickle\n",
    "!pip install jep==3.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATJ4YPAS2TQm"
   },
   "source": [
    "## **Distributed PyTorch using Orca APIs**\n",
    "\n",
    "In this guide we will describe how to scale out PyTorch programs using Orca in 4 simple steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXeY_v2S24bN"
   },
   "outputs": [],
   "source": [
    "# import necesary libraries and modules\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from zoo.orca import init_orca_context, stop_orca_context\n",
    "from zoo.orca import OrcaContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dn6xcsq43FRQ"
   },
   "source": [
    "### **Step 1: Init Orca Context**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXMGhKPk3GYN"
   },
   "outputs": [],
   "source": [
    "# recommended to set it to True when running Analytics Zoo in Jupyter notebook. \n",
    "OrcaContext.log_output = True # (this will display terminal's stdout and stderr in the Jupyter notebook).\n",
    "\n",
    "cluster_mode = \"local\"\n",
    "\n",
    "if cluster_mode == \"local\":\n",
    "    init_orca_context(cores=1, memory=\"2g\") # run in local mode\n",
    "elif cluster_mode == \"k8s\":\n",
    "    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=4) # run on K8s cluster\n",
    "elif cluster_mode == \"yarn\":\n",
    "    init_orca_context(\n",
    "        cluster_mode=\"yarn-client\", cores=4, num_nodes=2, memory=\"2g\",\n",
    "        driver_memory=\"10g\", driver_cores=1,\n",
    "        conf={\"spark.rpc.message.maxSize\": \"1024\",\n",
    "              \"spark.task.maxFailures\": \"1\",\n",
    "              \"spark.driver.extraJavaOptions\": \"-Dbigdl.failure.retryTimes=1\"}) # run on Hadoop YARN cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbu_llz48oNL"
   },
   "source": [
    "This is the only place where you need to specify local or distributed mode. View [Orca Context](https://analytics-zoo.readthedocs.io/en/latest/doc/Orca/Overview/orca-context.html) for more details.\n",
    "\n",
    "**Note**: You should export HADOOP_CONF_DIR=/path/to/hadoop/conf/dir when you run on Hadoop YARN cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBzXvR3LNxBP"
   },
   "source": [
    "### **Step 2: Define the Model**\n",
    "You may define your model, loss and optimizer in the same way as in any standard (single node) PyTorch program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZASG0afNWxd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = LeNet()\n",
    "model.train()\n",
    "criterion = nn.NLLLoss()\n",
    "lr = 0.001\n",
    "\n",
    "adam = torch.optim.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-SeParPNtK8"
   },
   "source": [
    "### **Step 3: Define Train Dataset**\n",
    "\n",
    "You may use a Data Creator Function for your input data (as shown below), especially when the data size is very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "!tar -zxvf MNIST.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQMxn902OBoR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "torch.manual_seed(0)\n",
    "dir='./'\n",
    "\n",
    "def train_loader_creator(config, batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "    return train_loader\n",
    "\n",
    "def test_loader_creator(config, batch_size):\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./', train=False,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=False)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLSjmlkROzPr"
   },
   "source": [
    "### **Step 4: Fit with Orca Estimator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49Rq_fo2O34O"
   },
   "source": [
    "First, Create an Estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-AK6mFKO4o5"
   },
   "outputs": [],
   "source": [
    "from zoo.orca.learn.pytorch import Estimator \n",
    "from zoo.orca.learn.metrics import Accuracy\n",
    "\n",
    "est = Estimator.from_torch(model=model, optimizer=adam, loss=criterion, metrics=[Accuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PEmVuGnPFBk"
   },
   "source": [
    "Next, fit and evaluate using the Estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeCoGJrGPH5M"
   },
   "outputs": [],
   "source": [
    "from zoo.orca.learn.trigger import EveryEpoch \n",
    "\n",
    "est.fit(data=train_loader_creator, epochs=1, validation_data=test_loader_creator, batch_size=320,\n",
    "        checkpoint_trigger=EveryEpoch())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFQCQwH0UBF1"
   },
   "source": [
    "Finally, evaluate using the Estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3cUxgYwUCUl"
   },
   "outputs": [],
   "source": [
    "result = est.evaluate(data=test_loader_creator, batch_size=320)\n",
    "for r in result:\n",
    "    print(r, \":\", result[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YASrq-VzXdpJ"
   },
   "source": [
    "The accuracy of this model has reached 98%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSSReIykRPIB"
   },
   "outputs": [],
   "source": [
    "# stop orca context when program finishes\n",
    "stop_orca_context()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "pytorch_lenet_mnist.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
