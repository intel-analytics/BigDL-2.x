{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the high level transfer learning APIs, you can easily customize pretrained models for feature extraction or fine-tuning. \n",
    "\n",
    "In this notebook, we will use a pre-trained Inception_V1 model. But we will operate on the pre-trained model to freeze first few layers, replace the classifier on the top, then fine tune the whole model. And we use the fine-tuned model to solve the dogs-vs-cats classification problem,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get the dogs-vs-cats datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the training dataset from https://www.kaggle.com/c/dogs-vs-cats and extract it. \n",
    "\n",
    "The following commands copy about 1100 images of cats and dogs into demo/cats and demo/dogs separately. \n",
    "```shell\n",
    "mkdir -p demo/dogs\n",
    "mkdir -p demo/cats\n",
    "cp train/cat.7* demo/cats\n",
    "cp train/dog.7* demo/dogs```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get the pre-trained Inception-V1 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the pre-trained Inception-V1 model from [Zoo](https://s3-ap-southeast-1.amazonaws.com/bigdl-models/imageclassification/imagenet/bigdl_inception-v1_imagenet_0.4.0.model) \n",
    " Alternatively, user may also download pre-trained caffe/Tensorflow/keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createDefault\n",
      "creating: createSGD\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n",
      "creating: createSeqToTensor\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from bigdl.nn.criterion import CrossEntropyCriterion\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "\n",
    "from zoo.common.nncontext import *\n",
    "from zoo.feature.image import *\n",
    "from zoo.pipeline.api.keras.layers import Dense, Input, Flatten\n",
    "from zoo.pipeline.api.keras.models import *\n",
    "from zoo.pipeline.api.net import *\n",
    "from zoo.pipeline.nnframes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkConf = SparkConf().setAppName(\"ImageTransferLearningExample\")\n",
    "sc = init_nncontext(sparkConf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manually set model_path and image_path for training\n",
    "\n",
    "1. model_path = path to the pre-trained models. (E.g. path/to/model/bigdl_inception-v1_imagenet_0.4.0.model)\n",
    "\n",
    "2. image_path = path to the folder of the training images. (E.g. path/to/data/dogs-vs-cats/demo/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_path = \"path/to/model/bigdl_inception-v1_imagenet_0.4.0.model\"\n",
    "image_path = \"path/to/data/dogs-vs-cats/demo/*/*\"\n",
    "imageDF = NNImageReader.readImages(image_path, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+\n",
      "|               image|        name|label|\n",
      "+--------------------+------------+-----+\n",
      "|[file:/home/xiaxu...|cat.7125.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7580.jpg|  1.0|\n",
      "|[file:/home/xiaxu...| cat.771.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7701.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7232.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7901.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7295.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7250.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7782.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7273.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7076.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7886.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7279.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7364.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7079.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7957.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7566.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7370.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7596.jpg|  1.0|\n",
      "|[file:/home/xiaxu...|cat.7061.jpg|  1.0|\n",
      "+--------------------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "getName = udf(lambda row:\n",
    "                  re.search(r'(cat|dog)\\.([\\d]*)\\.jpg', row[0], re.IGNORECASE).group(0),\n",
    "                  StringType())\n",
    "getLabel = udf(lambda name: 1.0 if name.startswith('cat') else 2.0, DoubleType())\n",
    "\n",
    "labelDF = imageDF.withColumn(\"name\", getName(col(\"image\"))) \\\n",
    "        .withColumn(\"label\", getLabel(col('name')))\n",
    "(trainingDF, validationDF) = labelDF.randomSplit([0.9, 0.1])\n",
    "labelDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compose a pipeline that includes feature transform, pretrained model and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createRowToImageFeature\n",
      "creating: createImageResize\n",
      "creating: createImageCenterCrop\n",
      "creating: createImageChannelNormalize\n",
      "creating: createImageMatToTensor\n",
      "creating: createImageFeatureToTensor\n",
      "creating: createChainedPreprocessing\n"
     ]
    }
   ],
   "source": [
    "transformer = ChainedPreprocessing(\n",
    "        [RowToImageFeature(), ImageResize(256, 256), ImageCenterCrop(224, 224),\n",
    "         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageFeatureToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Net API to load a pre-trained model, including models saved by Analytics Zoo, BigDL, Torch, Caffe and Tensorflow. Please refer to [Net API Guide](https://analytics-zoo.github.io/master/#APIGuide/PipelineAPI/net/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = Net.load_bigdl(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the last few layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a model is loaded using Net, we can use the newGraph(output) api to define a Model with the output specified by the parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = full_model.new_graph([\"pool5/drop_7x7_s1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returning model's output layer is \"pool5/drop_7x7_s1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze some layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freeze layers from input to pool4/3x3_s2 inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_up_to([\"pool4/3x3_s2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a few new layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createZooKerasInput\n",
      "creating: createZooKerasFlatten\n",
      "creating: createZooKerasDense\n",
      "creating: createZooKerasModel\n",
      "creating: createCrossEntropyCriterion\n",
      "creating: createScalarToTensor\n",
      "creating: createFeatureLabelPreprocessing\n",
      "creating: createNNClassifier\n"
     ]
    }
   ],
   "source": [
    "inputNode = Input(name=\"input\", shape=(3, 224, 224))\n",
    "inception = model.to_keras()(inputNode)\n",
    "flatten = Flatten()(inception)\n",
    "logits = Dense(2)(flatten)\n",
    "lrModel = Model(inputNode, logits)\n",
    "classifier = NNClassifier(lrModel, CrossEntropyCriterion(), transformer) \\\n",
    "        .setLearningRate(0.003).setBatchSize(40).setMaxEpoch(1).setFeaturesCol(\"image\") \\\n",
    "        .setCachingSample(False)\n",
    "pipeline = Pipeline(stages=[classifier])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transfer learning can finish in a few minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createToTuple\n",
      "creating: createChainedPreprocessing\n",
      "creating: createTensorToSample\n",
      "creating: createChainedPreprocessing\n",
      "+--------------------+------------+-----+----------+\n",
      "|               image|        name|label|prediction|\n",
      "+--------------------+------------+-----+----------+\n",
      "|[file:/home/xiaxu...|cat.7013.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7019.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7035.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7038.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7039.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7044.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7046.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7049.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7071.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7072.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7076.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7077.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7096.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7108.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7116.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7120.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7125.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7131.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7132.jpg|  1.0|       1.0|\n",
      "|[file:/home/xiaxu...|cat.7137.jpg|  1.0|       1.0|\n",
      "+--------------------+------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "catdogModel = pipeline.fit(trainingDF)\n",
    "predictionDF = catdogModel.transform(validationDF).cache()\n",
    "predictionDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0316742 \n"
     ]
    }
   ],
   "source": [
    "correct = predictionDF.filter(\"label=prediction\").count()\n",
    "overall = predictionDF.count()\n",
    "accuracy = correct * 1.0 / overall\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model from transfer learning can achieve over 95% accuracy on the validation set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}